{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "from transformers import PretrainedConfig\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import BCELoss\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = './data'\n",
    "\n",
    "# create dataframe from sessions.json\n",
    "df = pd.read_json(f'{path_to_data}/sessions.json')\n",
    "df.head()\n",
    "\n",
    "# create dictionaries for switching between symptom and id\n",
    "id2sym = {}\n",
    "sym2id = {}\n",
    "\n",
    "with open(f'{path_to_data}/symptoms.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    for sym in data:\n",
    "        id2sym[sym['id']] = sym['name']\n",
    "        sym2id[sym['name']] = sym['id']\n",
    "        \n",
    "        \n",
    "# remove labels that have less than m occurrences\n",
    "m = 0\n",
    "\n",
    "labels_list = df['confirmed'].tolist()\n",
    "labels_list = sum(labels_list, [])\n",
    "c = Counter(labels_list)\n",
    "for i in range(len(df)):\n",
    "    to_remove = []\n",
    "    \n",
    "    # find labels that should be removed \n",
    "    for j in range(len(df['confirmed'][i])):\n",
    "        if c[df['confirmed'][i][j]] < m:\n",
    "            to_remove.append(j)\n",
    "            \n",
    "    # remove the labels\n",
    "    shift = 0\n",
    "    for j in range(len(to_remove)):\n",
    "        df['confirmed'][i].pop(to_remove[j]-shift)\n",
    "        shift += 1\n",
    "    \n",
    "        \n",
    "# add column with the symptom names\n",
    "sym_names = []\n",
    "\n",
    "for syms in df['confirmed']:\n",
    "    if len(syms) != 0:\n",
    "        sym_names.append([id2sym[x] for x in syms])\n",
    "    else:\n",
    "        sym_names.append([])\n",
    "\n",
    "df['labels'] = sym_names\n",
    "\n",
    "# remove all rows with no confirmed labels\n",
    "df = df[df['confirmed'].map(len) > 0]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Slut på medicin.</td>\n",
       "      <td>[Känd astma, Känd lungsjukdom]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Behöver att prata med psykolog angående använd...</td>\n",
       "      <td>[Nedstämdhet, Trötthet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Har fått besvärlig eksem på händerna</td>\n",
       "      <td>[Hudbesvär, Synliga hudbesvär]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muskelsvaghet och trötthet känner mig skakig o...</td>\n",
       "      <td>[Muskelsvaghet, Trötthet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Svår smärta i vänsterhanden/handleden precis n...</td>\n",
       "      <td>[Smärta i handled eller fingrar, Förvärras av ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                                   Slut på medicin.   \n",
       "1  Behöver att prata med psykolog angående använd...   \n",
       "2              Har fått besvärlig eksem på händerna    \n",
       "3  Muskelsvaghet och trötthet känner mig skakig o...   \n",
       "4  Svår smärta i vänsterhanden/handleden precis n...   \n",
       "\n",
       "                                              labels  \n",
       "0                     [Känd astma, Känd lungsjukdom]  \n",
       "1                            [Nedstämdhet, Trötthet]  \n",
       "2                     [Hudbesvär, Synliga hudbesvär]  \n",
       "3                          [Muskelsvaghet, Trötthet]  \n",
       "4  [Smärta i handled eller fingrar, Förvärras av ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('confirmed', inplace=True, axis=1)\n",
    "df.drop('suggested', inplace=True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose which transformer model to use\n",
    "path_to_bert = r'./bert/electra-small-swedish-cased-discriminator'\n",
    "#path_to_bert = r'./bert/bert-base-swedish-cased'\n",
    "\n",
    "tok = BertTokenizer.from_pretrained(path_to_bert)\n",
    "\n",
    "# train a multilabel_binarizer on the labels\n",
    "labels = df['labels'].tolist()\n",
    "multilab_bin = MultiLabelBinarizer()\n",
    "multilab_bin.fit(labels)\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, multilab_bin, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.multilab_bin = multilab_bin\n",
    "        self.data = dataframe\n",
    "        self.text = self.data['text']\n",
    "        self.labels = self.data['labels']\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            #pad_to_max_length=True,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs['token_type_ids']\n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'labels': torch.tensor(np.sum(self.multilab_bin.transform([self.labels[index]]), axis=0), dtype=torch.float)\n",
    "        }        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 3027 samples\n",
      "Test set: 757 samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# max number of tokens in text\n",
    "max_len = 250\n",
    "\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(df,\n",
    "                                        random_state=42,\n",
    "                                        test_size=0.2,\n",
    "                                        shuffle=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "test_dataset = test_dataset.reset_index(drop=True)\n",
    "\n",
    "train_set = CustomDataset(train_dataset, tok, multilab_bin, max_len)\n",
    "test_set = CustomDataset(test_dataset, tok, multilab_bin, max_len)\n",
    "\n",
    "train_params = {'batch_size': batch_size,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "               }\n",
    "test_params = {'batch_size': batch_size,\n",
    "               'shuffle': True,\n",
    "               'num_workers': 0\n",
    "              }\n",
    "\n",
    "train_loader = DataLoader(train_set, **train_params)\n",
    "test_loader = DataLoader(test_set, **test_params)\n",
    "\n",
    "print(f'Train set: {len(train_dataset)} samples')\n",
    "print(f'Test set: {len(test_dataset)} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev = cpu\n",
      "Number of available GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "# decide which device to use. use cuda if available\n",
    "dev = ''\n",
    "if torch.cuda.is_available():\n",
    "    dev = 'cuda:0'\n",
    "else:\n",
    "    dev = 'cpu'\n",
    "    \n",
    "# TEMP: use cpu only (BERT model is very large)\n",
    "dev = 'cpu'\n",
    "\n",
    "print(f'dev = {dev}')\n",
    "print(f'Number of available GPUs: {torch.cuda.device_count()}')\n",
    "\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClass(nn.Module):\n",
    "    def __init__(self, output_dim, config):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(path_to_bert)\n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.fc = nn.Linear(config.hidden_size, output_dim)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        x = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
    "        x = self.dropout(x[1])\n",
    "        x = self.fc(x)\n",
    "        output = self.sigm(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss of an epoch by averaging all batch losses\n",
    "def epoch_loss(model, data_loader, criterion):\n",
    "    loss = 0\n",
    "    batch_count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx,batch in enumerate(data_loader):\n",
    "            ids = batch['ids'].to(device, dtype=torch.long)\n",
    "            mask = batch['mask'].to(device, dtype=torch.long)\n",
    "            token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "            labels = batch['labels'].to(device, dtype=torch.float)\n",
    "            \n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            loss += criterion(outputs, labels)\n",
    "            batch_count += 1\n",
    "    \n",
    "    return loss / batch_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./bert/electra-small-swedish-cased-discriminator were not used when initializing BertModel: ['electra.embeddings.position_ids', 'electra.embeddings.word_embeddings.weight', 'electra.embeddings.position_embeddings.weight', 'electra.embeddings.token_type_embeddings.weight', 'electra.embeddings.LayerNorm.weight', 'electra.embeddings.LayerNorm.bias', 'electra.embeddings_project.weight', 'electra.embeddings_project.bias', 'electra.encoder.layer.0.attention.self.query.weight', 'electra.encoder.layer.0.attention.self.query.bias', 'electra.encoder.layer.0.attention.self.key.weight', 'electra.encoder.layer.0.attention.self.key.bias', 'electra.encoder.layer.0.attention.self.value.weight', 'electra.encoder.layer.0.attention.self.value.bias', 'electra.encoder.layer.0.attention.output.dense.weight', 'electra.encoder.layer.0.attention.output.dense.bias', 'electra.encoder.layer.0.attention.output.LayerNorm.weight', 'electra.encoder.layer.0.attention.output.LayerNorm.bias', 'electra.encoder.layer.0.intermediate.dense.weight', 'electra.encoder.layer.0.intermediate.dense.bias', 'electra.encoder.layer.0.output.dense.weight', 'electra.encoder.layer.0.output.dense.bias', 'electra.encoder.layer.0.output.LayerNorm.weight', 'electra.encoder.layer.0.output.LayerNorm.bias', 'electra.encoder.layer.1.attention.self.query.weight', 'electra.encoder.layer.1.attention.self.query.bias', 'electra.encoder.layer.1.attention.self.key.weight', 'electra.encoder.layer.1.attention.self.key.bias', 'electra.encoder.layer.1.attention.self.value.weight', 'electra.encoder.layer.1.attention.self.value.bias', 'electra.encoder.layer.1.attention.output.dense.weight', 'electra.encoder.layer.1.attention.output.dense.bias', 'electra.encoder.layer.1.attention.output.LayerNorm.weight', 'electra.encoder.layer.1.attention.output.LayerNorm.bias', 'electra.encoder.layer.1.intermediate.dense.weight', 'electra.encoder.layer.1.intermediate.dense.bias', 'electra.encoder.layer.1.output.dense.weight', 'electra.encoder.layer.1.output.dense.bias', 'electra.encoder.layer.1.output.LayerNorm.weight', 'electra.encoder.layer.1.output.LayerNorm.bias', 'electra.encoder.layer.2.attention.self.query.weight', 'electra.encoder.layer.2.attention.self.query.bias', 'electra.encoder.layer.2.attention.self.key.weight', 'electra.encoder.layer.2.attention.self.key.bias', 'electra.encoder.layer.2.attention.self.value.weight', 'electra.encoder.layer.2.attention.self.value.bias', 'electra.encoder.layer.2.attention.output.dense.weight', 'electra.encoder.layer.2.attention.output.dense.bias', 'electra.encoder.layer.2.attention.output.LayerNorm.weight', 'electra.encoder.layer.2.attention.output.LayerNorm.bias', 'electra.encoder.layer.2.intermediate.dense.weight', 'electra.encoder.layer.2.intermediate.dense.bias', 'electra.encoder.layer.2.output.dense.weight', 'electra.encoder.layer.2.output.dense.bias', 'electra.encoder.layer.2.output.LayerNorm.weight', 'electra.encoder.layer.2.output.LayerNorm.bias', 'electra.encoder.layer.3.attention.self.query.weight', 'electra.encoder.layer.3.attention.self.query.bias', 'electra.encoder.layer.3.attention.self.key.weight', 'electra.encoder.layer.3.attention.self.key.bias', 'electra.encoder.layer.3.attention.self.value.weight', 'electra.encoder.layer.3.attention.self.value.bias', 'electra.encoder.layer.3.attention.output.dense.weight', 'electra.encoder.layer.3.attention.output.dense.bias', 'electra.encoder.layer.3.attention.output.LayerNorm.weight', 'electra.encoder.layer.3.attention.output.LayerNorm.bias', 'electra.encoder.layer.3.intermediate.dense.weight', 'electra.encoder.layer.3.intermediate.dense.bias', 'electra.encoder.layer.3.output.dense.weight', 'electra.encoder.layer.3.output.dense.bias', 'electra.encoder.layer.3.output.LayerNorm.weight', 'electra.encoder.layer.3.output.LayerNorm.bias', 'electra.encoder.layer.4.attention.self.query.weight', 'electra.encoder.layer.4.attention.self.query.bias', 'electra.encoder.layer.4.attention.self.key.weight', 'electra.encoder.layer.4.attention.self.key.bias', 'electra.encoder.layer.4.attention.self.value.weight', 'electra.encoder.layer.4.attention.self.value.bias', 'electra.encoder.layer.4.attention.output.dense.weight', 'electra.encoder.layer.4.attention.output.dense.bias', 'electra.encoder.layer.4.attention.output.LayerNorm.weight', 'electra.encoder.layer.4.attention.output.LayerNorm.bias', 'electra.encoder.layer.4.intermediate.dense.weight', 'electra.encoder.layer.4.intermediate.dense.bias', 'electra.encoder.layer.4.output.dense.weight', 'electra.encoder.layer.4.output.dense.bias', 'electra.encoder.layer.4.output.LayerNorm.weight', 'electra.encoder.layer.4.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.self.query.weight', 'electra.encoder.layer.5.attention.self.query.bias', 'electra.encoder.layer.5.attention.self.key.weight', 'electra.encoder.layer.5.attention.self.key.bias', 'electra.encoder.layer.5.attention.self.value.weight', 'electra.encoder.layer.5.attention.self.value.bias', 'electra.encoder.layer.5.attention.output.dense.weight', 'electra.encoder.layer.5.attention.output.dense.bias', 'electra.encoder.layer.5.attention.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.output.LayerNorm.bias', 'electra.encoder.layer.5.intermediate.dense.weight', 'electra.encoder.layer.5.intermediate.dense.bias', 'electra.encoder.layer.5.output.dense.weight', 'electra.encoder.layer.5.output.dense.bias', 'electra.encoder.layer.5.output.LayerNorm.weight', 'electra.encoder.layer.5.output.LayerNorm.bias', 'electra.encoder.layer.6.attention.self.query.weight', 'electra.encoder.layer.6.attention.self.query.bias', 'electra.encoder.layer.6.attention.self.key.weight', 'electra.encoder.layer.6.attention.self.key.bias', 'electra.encoder.layer.6.attention.self.value.weight', 'electra.encoder.layer.6.attention.self.value.bias', 'electra.encoder.layer.6.attention.output.dense.weight', 'electra.encoder.layer.6.attention.output.dense.bias', 'electra.encoder.layer.6.attention.output.LayerNorm.weight', 'electra.encoder.layer.6.attention.output.LayerNorm.bias', 'electra.encoder.layer.6.intermediate.dense.weight', 'electra.encoder.layer.6.intermediate.dense.bias', 'electra.encoder.layer.6.output.dense.weight', 'electra.encoder.layer.6.output.dense.bias', 'electra.encoder.layer.6.output.LayerNorm.weight', 'electra.encoder.layer.6.output.LayerNorm.bias', 'electra.encoder.layer.7.attention.self.query.weight', 'electra.encoder.layer.7.attention.self.query.bias', 'electra.encoder.layer.7.attention.self.key.weight', 'electra.encoder.layer.7.attention.self.key.bias', 'electra.encoder.layer.7.attention.self.value.weight', 'electra.encoder.layer.7.attention.self.value.bias', 'electra.encoder.layer.7.attention.output.dense.weight', 'electra.encoder.layer.7.attention.output.dense.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.weight', 'electra.encoder.layer.7.attention.output.LayerNorm.bias', 'electra.encoder.layer.7.intermediate.dense.weight', 'electra.encoder.layer.7.intermediate.dense.bias', 'electra.encoder.layer.7.output.dense.weight', 'electra.encoder.layer.7.output.dense.bias', 'electra.encoder.layer.7.output.LayerNorm.weight', 'electra.encoder.layer.7.output.LayerNorm.bias', 'electra.encoder.layer.8.attention.self.query.weight', 'electra.encoder.layer.8.attention.self.query.bias', 'electra.encoder.layer.8.attention.self.key.weight', 'electra.encoder.layer.8.attention.self.key.bias', 'electra.encoder.layer.8.attention.self.value.weight', 'electra.encoder.layer.8.attention.self.value.bias', 'electra.encoder.layer.8.attention.output.dense.weight', 'electra.encoder.layer.8.attention.output.dense.bias', 'electra.encoder.layer.8.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.attention.output.LayerNorm.bias', 'electra.encoder.layer.8.intermediate.dense.weight', 'electra.encoder.layer.8.intermediate.dense.bias', 'electra.encoder.layer.8.output.dense.weight', 'electra.encoder.layer.8.output.dense.bias', 'electra.encoder.layer.8.output.LayerNorm.weight', 'electra.encoder.layer.8.output.LayerNorm.bias', 'electra.encoder.layer.9.attention.self.query.weight', 'electra.encoder.layer.9.attention.self.query.bias', 'electra.encoder.layer.9.attention.self.key.weight', 'electra.encoder.layer.9.attention.self.key.bias', 'electra.encoder.layer.9.attention.self.value.weight', 'electra.encoder.layer.9.attention.self.value.bias', 'electra.encoder.layer.9.attention.output.dense.weight', 'electra.encoder.layer.9.attention.output.dense.bias', 'electra.encoder.layer.9.attention.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.output.LayerNorm.bias', 'electra.encoder.layer.9.intermediate.dense.weight', 'electra.encoder.layer.9.intermediate.dense.bias', 'electra.encoder.layer.9.output.dense.weight', 'electra.encoder.layer.9.output.dense.bias', 'electra.encoder.layer.9.output.LayerNorm.weight', 'electra.encoder.layer.9.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.self.query.weight', 'electra.encoder.layer.10.attention.self.query.bias', 'electra.encoder.layer.10.attention.self.key.weight', 'electra.encoder.layer.10.attention.self.key.bias', 'electra.encoder.layer.10.attention.self.value.weight', 'electra.encoder.layer.10.attention.self.value.bias', 'electra.encoder.layer.10.attention.output.dense.weight', 'electra.encoder.layer.10.attention.output.dense.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.weight', 'electra.encoder.layer.10.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.intermediate.dense.weight', 'electra.encoder.layer.10.intermediate.dense.bias', 'electra.encoder.layer.10.output.dense.weight', 'electra.encoder.layer.10.output.dense.bias', 'electra.encoder.layer.10.output.LayerNorm.weight', 'electra.encoder.layer.10.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.self.query.weight', 'electra.encoder.layer.11.attention.self.query.bias', 'electra.encoder.layer.11.attention.self.key.weight', 'electra.encoder.layer.11.attention.self.key.bias', 'electra.encoder.layer.11.attention.self.value.weight', 'electra.encoder.layer.11.attention.self.value.bias', 'electra.encoder.layer.11.attention.output.dense.weight', 'electra.encoder.layer.11.attention.output.dense.bias', 'electra.encoder.layer.11.attention.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.bias', 'electra.encoder.layer.11.intermediate.dense.weight', 'electra.encoder.layer.11.intermediate.dense.bias', 'electra.encoder.layer.11.output.dense.weight', 'electra.encoder.layer.11.output.dense.bias', 'electra.encoder.layer.11.output.LayerNorm.weight', 'electra.encoder.layer.11.output.LayerNorm.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at ./bert/electra-small-swedish-cased-discriminator and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Batch 2\n",
      "Batch 3\n",
      "Batch 4\n",
      "Batch 5\n",
      "Batch 6\n",
      "Batch 7\n",
      "Batch 8\n",
      "Batch 9\n",
      "Batch 10\n",
      "Batch 11\n",
      "Batch 12\n",
      "Batch 13\n",
      "Batch 14\n",
      "Batch 15\n",
      "Batch 16\n",
      "Batch 17\n",
      "Batch 18\n",
      "Batch 19\n",
      "Batch 20\n",
      "Batch 21\n",
      "Batch 22\n",
      "Batch 23\n",
      "Batch 24\n",
      "End of epoch 1, Train Loss: 0.1835149\n",
      "Batch 1\n",
      "Batch 2\n",
      "Batch 3\n",
      "Batch 4\n",
      "Batch 5\n",
      "Batch 6\n",
      "Batch 7\n",
      "Batch 8\n",
      "Batch 9\n",
      "Batch 10\n",
      "Batch 11\n",
      "Batch 12\n",
      "Batch 13\n",
      "Batch 14\n",
      "Batch 15\n",
      "Batch 16\n",
      "Batch 17\n",
      "Batch 18\n",
      "Batch 19\n",
      "Batch 20\n",
      "Batch 21\n",
      "Batch 22\n",
      "Batch 23\n",
      "Batch 24\n",
      "End of epoch 2, Train Loss: 0.0711880\n",
      "Batch 1\n",
      "Batch 2\n",
      "Batch 3\n",
      "Batch 4\n",
      "Batch 5\n",
      "Batch 6\n",
      "Batch 7\n",
      "Batch 8\n",
      "Batch 9\n",
      "Batch 10\n",
      "Batch 11\n",
      "Batch 12\n",
      "Batch 13\n",
      "Batch 14\n",
      "Batch 15\n",
      "Batch 16\n",
      "Batch 17\n",
      "Batch 18\n",
      "Batch 19\n",
      "Batch 20\n",
      "Batch 21\n",
      "Batch 22\n",
      "Batch 23\n",
      "Batch 24\n",
      "End of epoch 3, Train Loss: 0.0538410\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "D_out = len(multilab_bin.classes_)\n",
    "config = PretrainedConfig.from_json_file(f'{path_to_bert}/config.json')\n",
    "\n",
    "model = BERTClass(D_out, config)\n",
    "model.to(device)\n",
    "\n",
    "# training loop\n",
    "learning_rate = 0.0003\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# losses over entire train-/test-set per epoch\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    for idx,batch in enumerate(train_loader):\n",
    "        ids = batch['ids'].to(device, dtype=torch.long)\n",
    "        mask = batch['mask'].to(device, dtype=torch.long)\n",
    "        token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "        labels = batch['labels'].to(device, dtype=torch.float)\n",
    "        \n",
    "        print(f'Batch {idx+1}')\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # backward pass\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # save losses\n",
    "        train_losses.append(loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # save the losses\n",
    "    #train_losses.append(epoch_loss(model, train_loader, criterion))\n",
    "    #test_losses.append(epoch_loss(model, test_loader, criterion))\n",
    "    \n",
    "    print(f'End of epoch {epoch+1}, Train Loss: {train_losses[-1]:.7f}')# Test Loss: {test_losses[-1]:.7f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predicitons and corresponding labels\n",
    "def get_pred_true(model, data_loader, D_out):\n",
    "    y_pred = np.zeros((1,D_out))\n",
    "    y_true = np.zeros((1,D_out))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx,batch in enumerate(data_loader):\n",
    "            ids = batch['ids'].to(device, dtype=torch.long)\n",
    "            mask = batch['mask'].to(device, dtype=torch.long)\n",
    "            token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "            labels = batch['labels'].to(device, dtype=torch.float)\n",
    "            \n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            \n",
    "            y_pred = np.concatenate((np.array(y_pred),outputs.numpy()), axis=0)\n",
    "            y_true = np.concatenate((y_true,np.array(labels)), axis=0)\n",
    "            \n",
    "    return y_pred[1:,:], y_true[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_temp, y_true = get_pred_true(model, test_loader, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels in test set: 140/197 (71.07 %)\n",
      "Micro-average F1-score: 0.2715209254848588\n",
      "Weighted-average F1-score: 0.12088008155104368\n",
      "Macro-average F1-score: 0.29368842442229237\n",
      "Sample-average Jaccard score: 0.22212681638044912\n",
      "Accuracy (exact match): 0.14663143989431968\n",
      "Hamming Loss: 0.014356697892428702\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set all values above threshold to 1, else 0\n",
    "th = 0.2\n",
    "y_pred = np.copy(y_pred_temp)\n",
    "y_pred[y_pred > th] = 1\n",
    "y_pred[y_pred <= th] = 0\n",
    "\n",
    "# number of labels in test set\n",
    "labels_in_test = np.count_nonzero(np.sum(y_true, axis=0))\n",
    "\n",
    "print(f'Number of labels in test set: {labels_in_test}/{y_true.shape[1]} ({labels_in_test/y_true.shape[1]*100:.2f} %)')\n",
    "print(f\"Micro-average F1-score: {f1_score(y_true, y_pred, average='micro')}\")\n",
    "print(f\"Weighted-average F1-score: {f1_score(y_true, y_pred, average='weighted', zero_division=1)}\")\n",
    "print(f\"Macro-average F1-score: {f1_score(y_true, y_pred, average='macro', zero_division=1)}\")\n",
    "print(f\"Sample-average Jaccard score: {jaccard_score(y_true, y_pred, average='samples', zero_division=1)}\")\n",
    "print(f\"Accuracy (exact match): {accuracy_score(y_true, y_pred)}\")\n",
    "print(f\"Hamming Loss: {hamming_loss(y_true, y_pred)}\")\n",
    "\n",
    "x = [x for x in range(0,len(train_losses))]\n",
    "ticks = [x*10 for x in range(0,len(train_losses)//10+1)]\n",
    "#plt.plot(x, test_losses)\n",
    "plt.plot(x, train_losses)\n",
    "#plt.legend(['Test Loss', 'Train Loss'])\n",
    "plt.xticks(ticks, ticks)\n",
    "#plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "#plt.gca().set_ylim([0,0.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(test_dataset)):\n",
    "    text = str(test_dataset['text'][i])\n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "    inputs = tok.encode_plus(\n",
    "        text,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_token_type_ids=True\n",
    "    )\n",
    "    ids = torch.tensor(inputs['input_ids'], dtype=torch.long).view(1,-1)\n",
    "    mask = torch.tensor(inputs['attention_mask'], dtype=torch.long).view(1,-1)\n",
    "    token_type_ids = torch.tensor(inputs['token_type_ids'], dtype=torch.long).view(1,-1)\n",
    "    \n",
    "    y_pred_row = model(ids, mask, token_type_ids).detach().numpy()\n",
    "    \n",
    "    y_pred_row[y_pred_row > th] = 1\n",
    "    y_pred_row[y_pred_row <= th] = 0\n",
    "    \n",
    "    print(test_dataset['text'][i])\n",
    "    print(f'Prediction: {multilab_bin.inverse_transform(y_pred_row)}')\n",
    "    print(f'Labels: {test_dataset[\"labels\"][i]}')\n",
    "    print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
