{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "from transformers import PretrainedConfig\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import BCELoss\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = './data'\n",
    "\n",
    "# create dataframe from sessions.json\n",
    "df = pd.read_json(f'{path_to_data}/sessions.json')\n",
    "df.head()\n",
    "\n",
    "# create dictionaries for switching between symptom and id\n",
    "id2sym = {}\n",
    "sym2id = {}\n",
    "\n",
    "with open(f'{path_to_data}/symptoms.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    for sym in data:\n",
    "        id2sym[sym['id']] = sym['name']\n",
    "        sym2id[sym['name']] = sym['id']\n",
    "        \n",
    "        \n",
    "# remove labels that have less than m occurrences\n",
    "m = 0\n",
    "\n",
    "labels_list = df['confirmed'].tolist()\n",
    "labels_list = sum(labels_list, [])\n",
    "c = Counter(labels_list)\n",
    "for i in range(len(df)):\n",
    "    to_remove = []\n",
    "    \n",
    "    # find labels that should be removed \n",
    "    for j in range(len(df['confirmed'][i])):\n",
    "        if c[df['confirmed'][i][j]] < m:\n",
    "            to_remove.append(j)\n",
    "            \n",
    "    # remove the labels\n",
    "    shift = 0\n",
    "    for j in range(len(to_remove)):\n",
    "        df['confirmed'][i].pop(to_remove[j]-shift)\n",
    "        shift += 1\n",
    "    \n",
    "        \n",
    "# add column with the symptom names\n",
    "sym_names = []\n",
    "\n",
    "for syms in df['confirmed']:\n",
    "    if len(syms) != 0:\n",
    "        sym_names.append([id2sym[x] for x in syms])\n",
    "    else:\n",
    "        sym_names.append([])\n",
    "\n",
    "df['labels'] = sym_names\n",
    "\n",
    "# remove all rows with no confirmed labels\n",
    "df = df[df['confirmed'].map(len) > 0]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>suggested</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Slut på medicin.</td>\n",
       "      <td>[89, 651]</td>\n",
       "      <td>[348]</td>\n",
       "      <td>[Känd astma, Känd lungsjukdom]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Behöver att prata med psykolog angående använd...</td>\n",
       "      <td>[116, 215]</td>\n",
       "      <td>[215, 348, 446]</td>\n",
       "      <td>[Nedstämdhet, Trötthet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Har fått besvärlig eksem på händerna</td>\n",
       "      <td>[2, 141]</td>\n",
       "      <td>[141]</td>\n",
       "      <td>[Hudbesvär, Synliga hudbesvär]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muskelsvaghet och trötthet känner mig skakig o...</td>\n",
       "      <td>[606, 215]</td>\n",
       "      <td>[12, 97, 215, 359, 518, 606]</td>\n",
       "      <td>[Muskelsvaghet, Trötthet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Svår smärta i vänsterhanden/handleden precis n...</td>\n",
       "      <td>[682, 493]</td>\n",
       "      <td>[15, 28, 48, 54, 114, 148, 246, 313, 333, 339,...</td>\n",
       "      <td>[Smärta i handled eller fingrar, Förvärras av ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   confirmed  \\\n",
       "0                                   Slut på medicin.   [89, 651]   \n",
       "1  Behöver att prata med psykolog angående använd...  [116, 215]   \n",
       "2              Har fått besvärlig eksem på händerna     [2, 141]   \n",
       "3  Muskelsvaghet och trötthet känner mig skakig o...  [606, 215]   \n",
       "4  Svår smärta i vänsterhanden/handleden precis n...  [682, 493]   \n",
       "\n",
       "                                           suggested  \\\n",
       "0                                              [348]   \n",
       "1                                    [215, 348, 446]   \n",
       "2                                              [141]   \n",
       "3                       [12, 97, 215, 359, 518, 606]   \n",
       "4  [15, 28, 48, 54, 114, 148, 246, 313, 333, 339,...   \n",
       "\n",
       "                                              labels  \n",
       "0                     [Känd astma, Känd lungsjukdom]  \n",
       "1                            [Nedstämdhet, Trötthet]  \n",
       "2                     [Hudbesvär, Synliga hudbesvär]  \n",
       "3                          [Muskelsvaghet, Trötthet]  \n",
       "4  [Smärta i handled eller fingrar, Förvärras av ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_bert = r'./bert/bert-base-swedish-cased'\n",
    "tok = BertTokenizer.from_pretrained(path_to_bert)\n",
    "\n",
    "# train a multilabel_binarizer on the labels\n",
    "labels = df['labels'].tolist()\n",
    "multilab_bin = MultiLabelBinarizer()\n",
    "multilab_bin.fit(labels)\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, multilab_bin, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.multilab_bin = multilab_bin\n",
    "        self.data = dataframe\n",
    "        self.text = self.data['text']\n",
    "        self.labels = self.data['labels']\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            pad_to_max_length=True,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs['token_type_ids']\n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'labels': torch.tensor(np.sum(self.multilab_bin.transform([self.labels[index]]), axis=0), dtype=torch.float)\n",
    "        }        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(df,\n",
    "                                        random_state=42,\n",
    "                                        test_size=0.2,\n",
    "                                        shuffle=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "test_dataset = test_dataset.reset_index(drop=True)\n",
    "\n",
    "train_set = CustomDataset(train_dataset, tok, multilab_bin, 500)\n",
    "test_set = CustomDataset(test_dataset, tok, multilab_bin, 500)\n",
    "\n",
    "train_params = {'batch_size': batch_size,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "               }\n",
    "test_params = {'batch_size': batch_size,\n",
    "               'shuffle': True,\n",
    "               'num_workers': 0\n",
    "              }\n",
    "\n",
    "train_loader = DataLoader(train_set, **train_params)\n",
    "test_loader = DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev = cpu\n",
      "Number of available GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "# decide which device to use. use cuda if available\n",
    "dev = ''\n",
    "if torch.cuda.is_available():\n",
    "    dev = 'cuda:0'\n",
    "else:\n",
    "    dev = 'cpu'\n",
    "    \n",
    "# TEMP: use cpu only\n",
    "dev = 'cpu'\n",
    "\n",
    "print(f'dev = {dev}')\n",
    "print(f'Number of available GPUs: {torch.cuda.device_count()}')\n",
    "\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClass(nn.Module):\n",
    "    def __init__(self, output_dim, config):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(path_to_bert)\n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.fc = nn.Linear(config.hidden_size, output_dim)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        x = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
    "        #print(f'pool_out[1]: {pool_out[1].shape}')\n",
    "        x = self.dropout(x[1])\n",
    "        #print(dropout_out: {dropout_out.shape}')\n",
    "        x = self.fc(x)\n",
    "        #print(f'fc_out: {fc_out.shape}')\n",
    "        output = self.sigm(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss of an epoch by averaging all batch losses\n",
    "def epoch_loss(model, data_loader, criterion):\n",
    "    loss = 0\n",
    "    batch_count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx,batch in enumerate(data_loader):\n",
    "            ids = batch['ids'].to(device, dtype=torch.long)\n",
    "            mask = batch['mask'].to(device, dtype=torch.long)\n",
    "            token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "            labels = batch['labels'].to(device, dtype=torch.float)\n",
    "            \n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            loss += criterion(outputs, labels)\n",
    "            batch_count += 1\n",
    "    \n",
    "    return loss / batch_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Batch 2\n",
      "Batch 3\n",
      "Batch 4\n",
      "Batch 5\n",
      "Batch 6\n",
      "Batch 7\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'th' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f3d1ca06f2d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;31m# save the losses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[0mtest_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'th' is not defined"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "D_out = len(multilab_bin.classes_)\n",
    "config = PretrainedConfig.from_json_file(f'{path_to_bert}/config.json')\n",
    "\n",
    "model = BERTClass(D_out, config)\n",
    "model.to(device)\n",
    "\n",
    "# training loop\n",
    "learning_rate = 0.0003\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# losses over entire train-/test-set per epoch\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    for idx,batch in enumerate(train_loader):\n",
    "        ids = batch['ids'].to(device, dtype=torch.long)\n",
    "        mask = batch['mask'].to(device, dtype=torch.long)\n",
    "        token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "        labels = batch['labels'].to(device, dtype=torch.float)\n",
    "        \n",
    "        print(f'Batch {idx+1}')\n",
    "        #print('forward pass ...')\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # backward pass\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #print('backward pass')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # save the losses\n",
    "    train_losses.append(epoch_loss(model, train_loader, criterion))\n",
    "    test_losses.append(epoch_loss(model, test_loader, criterion))\n",
    "    \n",
    "    print(f'End of epoch {epoch+1}, Train Loss: {train_losses[-1]:.7f}, Test Loss: {test_losses[-1]:.7f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predicitons and corresponding labels\n",
    "def get_pred_true(model, data_loader, D_out):\n",
    "    y_pred = np.zeros((1,197))\n",
    "    y_true = np.zeros((1,197))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx,batch in enumerate(data_loader):\n",
    "            ids = batch['ids'].to(device, dtype=torch.long)\n",
    "            mask = batch['mask'].to(device, dtype=torch.long)\n",
    "            token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "            labels = batch['labels'].to(device, dtype=torch.float)\n",
    "            \n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            \n",
    "            y_pred = np.concatenate((np.array(y_pred),outputs.numpy()), axis=0)\n",
    "            y_true = np.concatenate((y_true,np.array(labels)), axis=0)\n",
    "\n",
    "    return y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 197)\n",
      "(1, 197)\n",
      "(20, 197)\n",
      "(21, 197)\n",
      "(20, 197)\n",
      "(41, 197)\n",
      "(20, 197)\n",
      "(61, 197)\n",
      "Micro-average F1-score: 0.02742561448900388\n",
      "Weighted-average F1-score: 0.28879462205641826\n",
      "Macro-average F1-score: 0.14101956942975025\n",
      "Sample-average Jaccard score: 0.026137703421278517\n",
      "Accuracy (exact match): 0.012345679012345678\n",
      "Hamming Loss: 0.47114119195337467\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-106adddec805>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Test Loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Train Loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred, y_true = get_pred_true(model, test_loader, D_out)\n",
    "\n",
    "# set all values above threshold to 1, else 0\n",
    "th = 0.2\n",
    "y_pred[y_pred > th] = 1\n",
    "y_pred[y_pred <= th] = 0\n",
    "\n",
    "print(f\"Micro-average F1-score: {f1_score(y_true, y_pred, average='micro')}\")\n",
    "print(f\"Weighted-average F1-score: {f1_score(y_true, y_pred, average='weighted', zero_division=1)}\")\n",
    "print(f\"Macro-average F1-score: {f1_score(y_true, y_pred, average='macro', zero_division=1)}\")\n",
    "print(f\"Sample-average Jaccard score: {jaccard_score(y_true, y_pred, average='samples', zero_division=1)}\")\n",
    "print(f\"Accuracy (exact match): {accuracy_score(y_true, y_pred)}\")\n",
    "print(f\"Hamming Loss: {hamming_loss(y_true, y_pred)}\")\n",
    "\n",
    "x = [x for x in range(1,num_epochs+1)]\n",
    "plt.plot(x, test_losses)\n",
    "plt.plot(x, train_losses)\n",
    "plt.legend(['Test Loss', 'Train Loss'])\n",
    "plt.xticks(x, x)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "#plt.gca().set_ylim([0,0.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
