{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "transformer_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReHiq1Llr_7M",
        "outputId": "2e30ec0f-a215-4280-9960-6ecf767f0ff2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqMdrxYy2iin",
        "outputId": "d66190ab-3e35-4ed2-eb5c-997504ed068e"
      },
      "source": [
        "import os\r\n",
        "\r\n",
        "if os.getcwd() == '/content':\r\n",
        "  % cd drive/MyDrive/exjobb_project\r\n",
        "\r\n",
        "print(os.getcwd())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/exjobb_project\n",
            "/content/drive/MyDrive/exjobb_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztQ8dAWOmau7"
      },
      "source": [
        "from transformers import BertModel\n",
        "from transformers import BertTokenizer\n",
        "from transformers import PretrainedConfig\n",
        "\n",
        "# metrics\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import jaccard_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import hamming_loss\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from torch.nn import BCELoss\n",
        "from collections import Counter\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuzjiHVMmau9"
      },
      "source": [
        "path_to_data = './data'\n",
        "\n",
        "# create dataframe from sessions.json\n",
        "df = pd.read_json(f'{path_to_data}/sessions.json')\n",
        "df.head()\n",
        "\n",
        "# create dictionaries for switching between symptom and id\n",
        "id2sym = {}\n",
        "sym2id = {}\n",
        "\n",
        "with open(f'{path_to_data}/symptoms.json') as json_file:\n",
        "    data = json.load(json_file)\n",
        "    for sym in data:\n",
        "        id2sym[sym['id']] = sym['name']\n",
        "        sym2id[sym['name']] = sym['id']\n",
        "        \n",
        "        \n",
        "# remove labels that have less than m occurrences\n",
        "m = 0\n",
        "\n",
        "labels_list = df['confirmed'].tolist()\n",
        "labels_list = sum(labels_list, [])\n",
        "c = Counter(labels_list)\n",
        "for i in range(len(df)):\n",
        "    to_remove = []\n",
        "    \n",
        "    # find labels that should be removed \n",
        "    for j in range(len(df['confirmed'][i])):\n",
        "        if c[df['confirmed'][i][j]] < m:\n",
        "            to_remove.append(j)\n",
        "            \n",
        "    # remove the labels\n",
        "    shift = 0\n",
        "    for j in range(len(to_remove)):\n",
        "        df['confirmed'][i].pop(to_remove[j]-shift)\n",
        "        shift += 1\n",
        "    \n",
        "        \n",
        "# add column with the symptom names\n",
        "sym_names = []\n",
        "\n",
        "for syms in df['confirmed']:\n",
        "    if len(syms) != 0:\n",
        "        sym_names.append([id2sym[x] for x in syms])\n",
        "    else:\n",
        "        sym_names.append([])\n",
        "\n",
        "df['labels'] = sym_names\n",
        "\n",
        "# remove all rows with no confirmed labels\n",
        "df = df[df['confirmed'].map(len) > 0]\n",
        "df = df.reset_index(drop=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "m9xph3WAmau-",
        "outputId": "7f90d977-9401-4e07-d2ba-06a9db18dde4"
      },
      "source": [
        "df.drop('confirmed', inplace=True, axis=1)\n",
        "df.drop('suggested', inplace=True, axis=1)\n",
        "#df = df[0:100]\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Slut på medicin.</td>\n",
              "      <td>[Känd astma, Känd lungsjukdom]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Behöver att prata med psykolog angående använd...</td>\n",
              "      <td>[Nedstämdhet, Trötthet]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Har fått besvärlig eksem på händerna</td>\n",
              "      <td>[Hudbesvär, Synliga hudbesvär]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Muskelsvaghet och trötthet känner mig skakig o...</td>\n",
              "      <td>[Muskelsvaghet, Trötthet]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Svår smärta i vänsterhanden/handleden precis n...</td>\n",
              "      <td>[Smärta i handled eller fingrar, Förvärras av ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text                                             labels\n",
              "0                                   Slut på medicin.                     [Känd astma, Känd lungsjukdom]\n",
              "1  Behöver att prata med psykolog angående använd...                            [Nedstämdhet, Trötthet]\n",
              "2              Har fått besvärlig eksem på händerna                      [Hudbesvär, Synliga hudbesvär]\n",
              "3  Muskelsvaghet och trötthet känner mig skakig o...                          [Muskelsvaghet, Trötthet]\n",
              "4  Svår smärta i vänsterhanden/handleden precis n...  [Smärta i handled eller fingrar, Förvärras av ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp_L0-yhmau_"
      },
      "source": [
        "# choose which transformer model to use\n",
        "path_to_bert = r'./bert/electra-small-swedish-cased-discriminator'\n",
        "#path_to_bert = r'./bert/bert-base-swedish-cased'\n",
        "\n",
        "tok = BertTokenizer.from_pretrained(path_to_bert)\n",
        "\n",
        "# train a multilabel_binarizer on the labels\n",
        "labels = df['labels'].tolist()\n",
        "multilab_bin = MultiLabelBinarizer()\n",
        "multilab_bin.fit(labels)\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, multilab_bin, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.multilab_bin = multilab_bin\n",
        "        self.data = dataframe\n",
        "        self.text = self.data['text']\n",
        "        self.labels = self.data['labels']\n",
        "        self.max_len = max_len\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = ' '.join(text.split())\n",
        "        \n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs['token_type_ids']\n",
        "        \n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'labels': torch.tensor(np.sum(self.multilab_bin.transform([self.labels[index]]), axis=0), dtype=torch.float)\n",
        "        }        "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqxfp2B8mau_",
        "outputId": "ebb05d11-f307-4270-aa3a-e58bdbd4a534"
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "# max number of tokens in text\n",
        "#max_len = 200\n",
        "max_len = 0\n",
        "for i in range(len(df['text'])):\n",
        "  text = df['text'][i]\n",
        "  inputs = tok.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            padding=False,\n",
        "            return_token_type_ids=True\n",
        "            )\n",
        "  if len(inputs['input_ids']) > max_len:\n",
        "    max_len = len(inputs['input_ids'])\n",
        "\n",
        "\n",
        "train_dataset, test_dataset = train_test_split(df,\n",
        "                                        random_state=42,\n",
        "                                        test_size=0.2,\n",
        "                                        shuffle=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "test_dataset = test_dataset.reset_index(drop=True)\n",
        "\n",
        "train_set = CustomDataset(train_dataset, tok, multilab_bin, max_len)\n",
        "test_set = CustomDataset(test_dataset, tok, multilab_bin, max_len)\n",
        "\n",
        "train_params = {'batch_size': batch_size,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "               }\n",
        "test_params = {'batch_size': batch_size,\n",
        "               'shuffle': True,\n",
        "               'num_workers': 0\n",
        "              }\n",
        "\n",
        "train_loader = DataLoader(train_set, **train_params)\n",
        "test_loader = DataLoader(test_set, **test_params)\n",
        "\n",
        "print(f'Train set: {len(train_dataset)} samples')\n",
        "print(f'Test set: {len(test_dataset)} samples')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set: 3027 samples\n",
            "Test set: 757 samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHjybrQHmau_",
        "outputId": "264b4142-0da4-477b-8f5c-b5c5694b992a"
      },
      "source": [
        "# decide which device to use. use cuda if available\n",
        "dev = ''\n",
        "if torch.cuda.is_available():\n",
        "    dev = 'cuda:0'\n",
        "else:\n",
        "    dev = 'cpu'\n",
        "\n",
        "print(f'dev = {dev}')\n",
        "print(f'Number of available GPUs: {torch.cuda.device_count()}')\n",
        "\n",
        "# print the device names\n",
        "for i in range(torch.cuda.device_count()):\n",
        "  print(f'Device {i}: {torch.cuda.get_device_name(i)}')\n",
        "\n",
        "device = torch.device(dev)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev = cuda:0\n",
            "Number of available GPUs: 1\n",
            "Device 0: Tesla P4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBYDTZNvmavA"
      },
      "source": [
        "class BERTClass(nn.Module):\n",
        "    def __init__(self, config, path_to_bert, output_dim):\n",
        "        super(BERTClass, self).__init__()\n",
        "        config = PretrainedConfig.from_json_file(f'{path_to_bert}/config.json')\n",
        "        self.bert = BertModel.from_pretrained(path_to_bert)\n",
        "        #self.bert = BertModel(config)\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.fc = nn.Linear(config.hidden_size, output_dim)\n",
        "        self.sigm = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        x = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
        "        x = self.dropout(x[1])\n",
        "        x = self.fc(x)\n",
        "        output = self.sigm(x)\n",
        "        return output"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGGhVr_tmavA"
      },
      "source": [
        "# compute the loss of an epoch by averaging all batch losses\n",
        "def epoch_loss(model, data_loader, criterion):\n",
        "    loss = 0\n",
        "    batch_count = 0\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx,batch in enumerate(data_loader):\n",
        "            ids = batch['ids'].to(device, dtype=torch.long)\n",
        "            mask = batch['mask'].to(device, dtype=torch.long)\n",
        "            token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
        "            labels = batch['labels'].to(device, dtype=torch.float)\n",
        "            \n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            loss += criterion(outputs, labels)\n",
        "            batch_count += 1\n",
        "    model.train()\n",
        "    return loss / batch_count"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr7rj2zwWj0K",
        "outputId": "b1acc21a-302f-43e6-fa34-7ee37c8f0c5e"
      },
      "source": [
        "# define the model\r\n",
        "D_out = len(multilab_bin.classes_)\r\n",
        "\r\n",
        "config = PretrainedConfig.from_json_file(f'{path_to_bert}/config.json')\r\n",
        "\r\n",
        "model = BERTClass(config, path_to_bert, D_out)\r\n",
        "model.train()\r\n",
        "model.to(device)\r\n",
        "\r\n",
        "# number of epochs trained\r\n",
        "epochs_trained = 0\r\n",
        "\r\n",
        "# losses over entire train-/test-set per epoch\r\n",
        "train_losses = []\r\n",
        "test_losses = []"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at ./bert/electra-small-swedish-cased-discriminator were not used when initializing BertModel: ['electra.embeddings.position_ids', 'electra.embeddings.word_embeddings.weight', 'electra.embeddings.position_embeddings.weight', 'electra.embeddings.token_type_embeddings.weight', 'electra.embeddings.LayerNorm.weight', 'electra.embeddings.LayerNorm.bias', 'electra.embeddings_project.weight', 'electra.embeddings_project.bias', 'electra.encoder.layer.0.attention.self.query.weight', 'electra.encoder.layer.0.attention.self.query.bias', 'electra.encoder.layer.0.attention.self.key.weight', 'electra.encoder.layer.0.attention.self.key.bias', 'electra.encoder.layer.0.attention.self.value.weight', 'electra.encoder.layer.0.attention.self.value.bias', 'electra.encoder.layer.0.attention.output.dense.weight', 'electra.encoder.layer.0.attention.output.dense.bias', 'electra.encoder.layer.0.attention.output.LayerNorm.weight', 'electra.encoder.layer.0.attention.output.LayerNorm.bias', 'electra.encoder.layer.0.intermediate.dense.weight', 'electra.encoder.layer.0.intermediate.dense.bias', 'electra.encoder.layer.0.output.dense.weight', 'electra.encoder.layer.0.output.dense.bias', 'electra.encoder.layer.0.output.LayerNorm.weight', 'electra.encoder.layer.0.output.LayerNorm.bias', 'electra.encoder.layer.1.attention.self.query.weight', 'electra.encoder.layer.1.attention.self.query.bias', 'electra.encoder.layer.1.attention.self.key.weight', 'electra.encoder.layer.1.attention.self.key.bias', 'electra.encoder.layer.1.attention.self.value.weight', 'electra.encoder.layer.1.attention.self.value.bias', 'electra.encoder.layer.1.attention.output.dense.weight', 'electra.encoder.layer.1.attention.output.dense.bias', 'electra.encoder.layer.1.attention.output.LayerNorm.weight', 'electra.encoder.layer.1.attention.output.LayerNorm.bias', 'electra.encoder.layer.1.intermediate.dense.weight', 'electra.encoder.layer.1.intermediate.dense.bias', 'electra.encoder.layer.1.output.dense.weight', 'electra.encoder.layer.1.output.dense.bias', 'electra.encoder.layer.1.output.LayerNorm.weight', 'electra.encoder.layer.1.output.LayerNorm.bias', 'electra.encoder.layer.2.attention.self.query.weight', 'electra.encoder.layer.2.attention.self.query.bias', 'electra.encoder.layer.2.attention.self.key.weight', 'electra.encoder.layer.2.attention.self.key.bias', 'electra.encoder.layer.2.attention.self.value.weight', 'electra.encoder.layer.2.attention.self.value.bias', 'electra.encoder.layer.2.attention.output.dense.weight', 'electra.encoder.layer.2.attention.output.dense.bias', 'electra.encoder.layer.2.attention.output.LayerNorm.weight', 'electra.encoder.layer.2.attention.output.LayerNorm.bias', 'electra.encoder.layer.2.intermediate.dense.weight', 'electra.encoder.layer.2.intermediate.dense.bias', 'electra.encoder.layer.2.output.dense.weight', 'electra.encoder.layer.2.output.dense.bias', 'electra.encoder.layer.2.output.LayerNorm.weight', 'electra.encoder.layer.2.output.LayerNorm.bias', 'electra.encoder.layer.3.attention.self.query.weight', 'electra.encoder.layer.3.attention.self.query.bias', 'electra.encoder.layer.3.attention.self.key.weight', 'electra.encoder.layer.3.attention.self.key.bias', 'electra.encoder.layer.3.attention.self.value.weight', 'electra.encoder.layer.3.attention.self.value.bias', 'electra.encoder.layer.3.attention.output.dense.weight', 'electra.encoder.layer.3.attention.output.dense.bias', 'electra.encoder.layer.3.attention.output.LayerNorm.weight', 'electra.encoder.layer.3.attention.output.LayerNorm.bias', 'electra.encoder.layer.3.intermediate.dense.weight', 'electra.encoder.layer.3.intermediate.dense.bias', 'electra.encoder.layer.3.output.dense.weight', 'electra.encoder.layer.3.output.dense.bias', 'electra.encoder.layer.3.output.LayerNorm.weight', 'electra.encoder.layer.3.output.LayerNorm.bias', 'electra.encoder.layer.4.attention.self.query.weight', 'electra.encoder.layer.4.attention.self.query.bias', 'electra.encoder.layer.4.attention.self.key.weight', 'electra.encoder.layer.4.attention.self.key.bias', 'electra.encoder.layer.4.attention.self.value.weight', 'electra.encoder.layer.4.attention.self.value.bias', 'electra.encoder.layer.4.attention.output.dense.weight', 'electra.encoder.layer.4.attention.output.dense.bias', 'electra.encoder.layer.4.attention.output.LayerNorm.weight', 'electra.encoder.layer.4.attention.output.LayerNorm.bias', 'electra.encoder.layer.4.intermediate.dense.weight', 'electra.encoder.layer.4.intermediate.dense.bias', 'electra.encoder.layer.4.output.dense.weight', 'electra.encoder.layer.4.output.dense.bias', 'electra.encoder.layer.4.output.LayerNorm.weight', 'electra.encoder.layer.4.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.self.query.weight', 'electra.encoder.layer.5.attention.self.query.bias', 'electra.encoder.layer.5.attention.self.key.weight', 'electra.encoder.layer.5.attention.self.key.bias', 'electra.encoder.layer.5.attention.self.value.weight', 'electra.encoder.layer.5.attention.self.value.bias', 'electra.encoder.layer.5.attention.output.dense.weight', 'electra.encoder.layer.5.attention.output.dense.bias', 'electra.encoder.layer.5.attention.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.output.LayerNorm.bias', 'electra.encoder.layer.5.intermediate.dense.weight', 'electra.encoder.layer.5.intermediate.dense.bias', 'electra.encoder.layer.5.output.dense.weight', 'electra.encoder.layer.5.output.dense.bias', 'electra.encoder.layer.5.output.LayerNorm.weight', 'electra.encoder.layer.5.output.LayerNorm.bias', 'electra.encoder.layer.6.attention.self.query.weight', 'electra.encoder.layer.6.attention.self.query.bias', 'electra.encoder.layer.6.attention.self.key.weight', 'electra.encoder.layer.6.attention.self.key.bias', 'electra.encoder.layer.6.attention.self.value.weight', 'electra.encoder.layer.6.attention.self.value.bias', 'electra.encoder.layer.6.attention.output.dense.weight', 'electra.encoder.layer.6.attention.output.dense.bias', 'electra.encoder.layer.6.attention.output.LayerNorm.weight', 'electra.encoder.layer.6.attention.output.LayerNorm.bias', 'electra.encoder.layer.6.intermediate.dense.weight', 'electra.encoder.layer.6.intermediate.dense.bias', 'electra.encoder.layer.6.output.dense.weight', 'electra.encoder.layer.6.output.dense.bias', 'electra.encoder.layer.6.output.LayerNorm.weight', 'electra.encoder.layer.6.output.LayerNorm.bias', 'electra.encoder.layer.7.attention.self.query.weight', 'electra.encoder.layer.7.attention.self.query.bias', 'electra.encoder.layer.7.attention.self.key.weight', 'electra.encoder.layer.7.attention.self.key.bias', 'electra.encoder.layer.7.attention.self.value.weight', 'electra.encoder.layer.7.attention.self.value.bias', 'electra.encoder.layer.7.attention.output.dense.weight', 'electra.encoder.layer.7.attention.output.dense.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.weight', 'electra.encoder.layer.7.attention.output.LayerNorm.bias', 'electra.encoder.layer.7.intermediate.dense.weight', 'electra.encoder.layer.7.intermediate.dense.bias', 'electra.encoder.layer.7.output.dense.weight', 'electra.encoder.layer.7.output.dense.bias', 'electra.encoder.layer.7.output.LayerNorm.weight', 'electra.encoder.layer.7.output.LayerNorm.bias', 'electra.encoder.layer.8.attention.self.query.weight', 'electra.encoder.layer.8.attention.self.query.bias', 'electra.encoder.layer.8.attention.self.key.weight', 'electra.encoder.layer.8.attention.self.key.bias', 'electra.encoder.layer.8.attention.self.value.weight', 'electra.encoder.layer.8.attention.self.value.bias', 'electra.encoder.layer.8.attention.output.dense.weight', 'electra.encoder.layer.8.attention.output.dense.bias', 'electra.encoder.layer.8.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.attention.output.LayerNorm.bias', 'electra.encoder.layer.8.intermediate.dense.weight', 'electra.encoder.layer.8.intermediate.dense.bias', 'electra.encoder.layer.8.output.dense.weight', 'electra.encoder.layer.8.output.dense.bias', 'electra.encoder.layer.8.output.LayerNorm.weight', 'electra.encoder.layer.8.output.LayerNorm.bias', 'electra.encoder.layer.9.attention.self.query.weight', 'electra.encoder.layer.9.attention.self.query.bias', 'electra.encoder.layer.9.attention.self.key.weight', 'electra.encoder.layer.9.attention.self.key.bias', 'electra.encoder.layer.9.attention.self.value.weight', 'electra.encoder.layer.9.attention.self.value.bias', 'electra.encoder.layer.9.attention.output.dense.weight', 'electra.encoder.layer.9.attention.output.dense.bias', 'electra.encoder.layer.9.attention.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.output.LayerNorm.bias', 'electra.encoder.layer.9.intermediate.dense.weight', 'electra.encoder.layer.9.intermediate.dense.bias', 'electra.encoder.layer.9.output.dense.weight', 'electra.encoder.layer.9.output.dense.bias', 'electra.encoder.layer.9.output.LayerNorm.weight', 'electra.encoder.layer.9.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.self.query.weight', 'electra.encoder.layer.10.attention.self.query.bias', 'electra.encoder.layer.10.attention.self.key.weight', 'electra.encoder.layer.10.attention.self.key.bias', 'electra.encoder.layer.10.attention.self.value.weight', 'electra.encoder.layer.10.attention.self.value.bias', 'electra.encoder.layer.10.attention.output.dense.weight', 'electra.encoder.layer.10.attention.output.dense.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.weight', 'electra.encoder.layer.10.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.intermediate.dense.weight', 'electra.encoder.layer.10.intermediate.dense.bias', 'electra.encoder.layer.10.output.dense.weight', 'electra.encoder.layer.10.output.dense.bias', 'electra.encoder.layer.10.output.LayerNorm.weight', 'electra.encoder.layer.10.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.self.query.weight', 'electra.encoder.layer.11.attention.self.query.bias', 'electra.encoder.layer.11.attention.self.key.weight', 'electra.encoder.layer.11.attention.self.key.bias', 'electra.encoder.layer.11.attention.self.value.weight', 'electra.encoder.layer.11.attention.self.value.bias', 'electra.encoder.layer.11.attention.output.dense.weight', 'electra.encoder.layer.11.attention.output.dense.bias', 'electra.encoder.layer.11.attention.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.bias', 'electra.encoder.layer.11.intermediate.dense.weight', 'electra.encoder.layer.11.intermediate.dense.bias', 'electra.encoder.layer.11.output.dense.weight', 'electra.encoder.layer.11.output.dense.bias', 'electra.encoder.layer.11.output.LayerNorm.weight', 'electra.encoder.layer.11.output.LayerNorm.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at ./bert/electra-small-swedish-cased-discriminator and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs7jzf1amavA",
        "outputId": "968c58da-ff50-437c-8563-bb023d2d45fd"
      },
      "source": [
        "model.train()\n",
        "\n",
        "# training loop\n",
        "learning_rate = 0.00005\n",
        "\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    for idx,batch in enumerate(train_loader):\n",
        "        ids = batch['ids'].to(device, dtype=torch.long)\n",
        "        mask = batch['mask'].to(device, dtype=torch.long)\n",
        "        token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
        "        labels = batch['labels'].to(device, dtype=torch.float)\n",
        "        \n",
        "        # forward pass\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "        \n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # backward pass\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    # save the losses\n",
        "    train_losses.append(epoch_loss(model, train_loader, criterion))\n",
        "    test_losses.append(epoch_loss(model, test_loader, criterion))\n",
        "\n",
        "    epochs_trained += 1\n",
        "    \n",
        "    print(f'End of epoch {epochs_trained}, Train Loss: {train_losses[-1]:.7f}, Test Loss: {test_losses[-1]:.7f}')\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "End of epoch 121, Train Loss: 0.0056945, Test Loss: 0.0286861\n",
            "End of epoch 122, Train Loss: 0.0054950, Test Loss: 0.0287357\n",
            "End of epoch 123, Train Loss: 0.0054990, Test Loss: 0.0289785\n",
            "End of epoch 124, Train Loss: 0.0054526, Test Loss: 0.0285787\n",
            "End of epoch 125, Train Loss: 0.0053906, Test Loss: 0.0291540\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-OJN96cmavB"
      },
      "source": [
        "# get the predicitons and corresponding labels\n",
        "def get_pred_true(model, data_loader, D_out):\n",
        "\n",
        "    y_pred = np.zeros((1,D_out))\n",
        "    y_true = np.zeros((1,D_out))\n",
        "  \n",
        "    with torch.no_grad():\n",
        "        for idx,batch in enumerate(data_loader):\n",
        "            ids = batch['ids'].to(device, dtype=torch.long)\n",
        "            mask = batch['mask'].to(device, dtype=torch.long)\n",
        "            token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
        "            labels = batch['labels'].to(device, dtype=torch.float)\n",
        "            \n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            \n",
        "            y_pred = np.concatenate((y_pred,outputs.detach().cpu().numpy()), axis=0)\n",
        "            y_true = np.concatenate((y_true,np.array(labels.cpu())), axis=0)\n",
        "            \n",
        "    return y_pred[1:,:], y_true[1:,:]\n",
        "\n",
        "model.eval()  \n",
        "y_pred_temp, y_true = get_pred_true(model, test_loader, D_out)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtdtWDQAmavC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "20f20ea2-f70a-4f4c-a2c6-25c5222a5e58"
      },
      "source": [
        "# set all values above threshold to 1, else 0\n",
        "th = 0.2\n",
        "y_pred = np.copy(y_pred_temp)\n",
        "y_pred[y_pred > th] = 1\n",
        "y_pred[y_pred <= th] = 0\n",
        "\n",
        "# number of labels in test set\n",
        "#labels_in_test = np.count_nonzero(np.sum(y_true, axis=0))\n",
        "label_counts_test = np.sum(multilab_bin.transform(test_dataset['labels']), axis=0)\n",
        "labels_in_test = np.count_nonzero(label_counts_test)\n",
        "\n",
        "# number of labels in train set\n",
        "label_counts_train = np.sum(multilab_bin.transform(train_dataset['labels']), axis=0)\n",
        "labels_in_train = np.count_nonzero(label_counts_train)\n",
        "\n",
        "# compute size of intersection between labels in train and test\n",
        "label_counts_test[label_counts_test > 0] = 1\n",
        "labels_bin_test = label_counts_test\n",
        "\n",
        "label_counts_train[label_counts_train > 0] = 1\n",
        "labels_bin_train = label_counts_train\n",
        "\n",
        "labels_bin_sum = labels_bin_test + labels_bin_train\n",
        "labels_intersect = np.count_nonzero(labels_bin_sum[labels_bin_sum == 2])\n",
        "\n",
        "print(f'Number of labels in training set: {labels_in_train}/{y_true.shape[1]} ({labels_in_train/y_true.shape[1]*100:.2f} %)')\n",
        "print(f'Number of labels in test set: {labels_in_test}/{y_true.shape[1]} ({labels_in_test/y_true.shape[1]*100:.2f} %)')\n",
        "print(f'Number of labels present in both sets: {labels_intersect}/{y_true.shape[1]} ({labels_intersect/y_true.shape[1]*100:.2f} %)')\n",
        "print()\n",
        "print(f\"Micro-average F1-score: {f1_score(y_true, y_pred, average='micro')}\")\n",
        "print(f\"Weighted-average F1-score: {f1_score(y_true, y_pred, average='weighted', zero_division=1)}\")\n",
        "print(f\"Macro-average F1-score: {f1_score(y_true, y_pred, average='macro', zero_division=1)}\")\n",
        "#print(f\"Sample-average Jaccard score: {jaccard_score(y_true, y_pred, average='samples', zero_division=1)}\")\n",
        "print(f\"Accuracy (exact match): {accuracy_score(y_true, y_pred)}\")\n",
        "print(f\"Hamming Loss: {hamming_loss(y_true, y_pred)}\")\n",
        "\n",
        "x = [x for x in range(1,len(train_losses)+1)]\n",
        "xticks = [x*len(train_losses)//5 for x in range(1,6)]\n",
        "plt.plot(x, test_losses)\n",
        "plt.plot(x, train_losses)\n",
        "plt.legend(['Test Loss', 'Train Loss'])\n",
        "plt.xticks(xticks,xticks)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "#plt.gca().set_ylim([0,0.1])\n",
        "plt.show()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of labels in training set: 186/197 (94.42 %)\n",
            "Number of labels in test set: 140/197 (71.07 %)\n",
            "Number of labels present in both sets: 129/197 (65.48 %)\n",
            "\n",
            "Micro-average F1-score: 0.6526966678117485\n",
            "Weighted-average F1-score: 0.6163234292938252\n",
            "Macro-average F1-score: 0.4232475683952546\n",
            "Accuracy (exact match): 0.36459709379128136\n",
            "Hamming Loss: 0.006779365515761522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "aZQ1B-mOmavC"
      },
      "source": [
        "model.eval()\n",
        "for i in range(len(test_dataset)):\n",
        "    text = str(test_dataset['text'][i])\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    inputs = tok.encode_plus(\n",
        "        text,\n",
        "        None,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_len,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        return_token_type_ids=True\n",
        "    )\n",
        "    ids = torch.tensor(inputs['input_ids'], dtype=torch.long).view(1,-1).to(device)\n",
        "    mask = torch.tensor(inputs['attention_mask'], dtype=torch.long).view(1,-1).to(device)\n",
        "    token_type_ids = torch.tensor(inputs['token_type_ids'], dtype=torch.long).view(1,-1).to(device)\n",
        "    \n",
        "    y_pred_row = model(ids, mask, token_type_ids).detach().cpu().numpy()\n",
        "    \n",
        "    y_pred_row[y_pred_row > th] = 1\n",
        "    y_pred_row[y_pred_row <= th] = 0\n",
        "    \n",
        "    print(test_dataset['text'][i])\n",
        "    print(f'Prediction: {multilab_bin.inverse_transform(y_pred_row)}')\n",
        "    print(f'Labels: {test_dataset[\"labels\"][i]}')\n",
        "    print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmnfecMFmavD"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}