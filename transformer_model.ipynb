{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "transformer_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReHiq1Llr_7M"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqMdrxYy2iin"
      },
      "source": [
        "import os\r\n",
        "\r\n",
        "if os.getcwd() == '/content':\r\n",
        "  % cd drive/MyDrive/exjobb_project\r\n",
        "\r\n",
        "print(os.getcwd())\r\n",
        "\r\n",
        "!pip install transformers\r\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztQ8dAWOmau7"
      },
      "source": [
        "from transformers import BertModel\n",
        "from transformers import BertTokenizer\n",
        "from transformers import PretrainedConfig\n",
        "from transformers import XLNetModel, XLNetTokenizer\n",
        "\n",
        "# testing different loading of models\n",
        "#from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "# metrics\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import jaccard_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import hamming_loss\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import json\n",
        "import time\n",
        "import regex as re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import UnivariateSpline\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from torch.nn import BCELoss\n",
        "from collections import Counter\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8gxL6oKgo2a"
      },
      "source": [
        "# use an RNG seed for reproducibility\r\n",
        "seed_list = [2, 4, 8]\r\n",
        "\r\n",
        "SEED = seed_list[1]\r\n",
        "\r\n",
        "# set the RNG seed\r\n",
        "np.random.seed(SEED)\r\n",
        "torch.manual_seed(SEED)\r\n",
        "\r\n",
        "# summary of current run\r\n",
        "summary = f'SEED: {SEED}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuzjiHVMmau9"
      },
      "source": [
        "path_to_data = './data'\n",
        "\n",
        "# create dataframe from sessions.json\n",
        "df = pd.read_json(f'{path_to_data}/sessions/sessions_02.json')\n",
        "df.head()\n",
        "\n",
        "# create dictionaries for switching between symptom and id\n",
        "id2sym = {}\n",
        "sym2id = {}\n",
        "\n",
        "with open(f'{path_to_data}/symptoms/symptoms_02.json') as json_file:\n",
        "    data = json.load(json_file)\n",
        "    for sym in data:\n",
        "        id2sym[sym['id']] = sym['name']\n",
        "        sym2id[sym['name']] = sym['id']\n",
        "        \n",
        "print(f'Numer of symptoms in id2sym: {len(sym2id)}')\n",
        "\n",
        "if False:\n",
        "    # remove labels that have less than m occurrences\n",
        "    m = 100\n",
        "\n",
        "    labels_list = df['confirmed'].tolist()\n",
        "    labels_list = sum(labels_list, [])\n",
        "    c = Counter(labels_list)\n",
        "    for i in range(len(df)):\n",
        "        to_remove = []\n",
        "        \n",
        "        # find labels that should be removed \n",
        "        for j in range(len(df['confirmed'][i])):\n",
        "            if c[df['confirmed'][i][j]] < m:\n",
        "                to_remove.append(j)\n",
        "                \n",
        "        # remove the labels\n",
        "        shift = 0\n",
        "        for j in range(len(to_remove)):\n",
        "            df['confirmed'][i].pop(to_remove[j]-shift)\n",
        "            shift += 1\n",
        "\n",
        "        \n",
        "# add column with the symptom names\n",
        "sym_names = []\n",
        "\n",
        "for syms in df['confirmed']:\n",
        "    if len(syms) != 0:\n",
        "        sym_names.append([id2sym[x] for x in syms])\n",
        "    else:\n",
        "        sym_names.append([])\n",
        "\n",
        "df['labels'] = sym_names\n",
        "\n",
        "# remove all rows with no confirmed labels\n",
        "df = df[df['confirmed'].map(len) > 0]\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "# remove unused columns\n",
        "df.drop('confirmed', inplace=True, axis=1)\n",
        "#df.drop('suggested', inplace=True, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9xph3WAmau-"
      },
      "source": [
        "# use only first limit samples\n",
        "#limit = int(len(df)/3)\n",
        "#df = df[:limit]\n",
        "\n",
        "print(f'Number of samples in df: {len(df)}')\n",
        "\n",
        "if False:\n",
        "    # check if there are duplicates and remove them if found\n",
        "    dup_set = set()\n",
        "    dup_count = 0\n",
        "\n",
        "    for ind, row in df.iterrows():\n",
        "        temp_tup = (row['text'], tuple(row['labels']))\n",
        "        if temp_tup in dup_set:\n",
        "            # remove text if the size is larger than 40\n",
        "            #if len(row['text']) > 40:\n",
        "                #print(f'Dropping index {ind} with text: {row[\"text\"]}')\n",
        "                df.drop(ind, inplace=True)\n",
        "                dup_count += 1\n",
        "        else:\n",
        "            dup_set.add((row['text'], tuple(row['labels'])))\n",
        "    df = df.reset_index(drop=True)\n",
        "\n",
        "    print(f'Removed {dup_count} duplicates')\n",
        "    print(f'Number of samples in df after removal: {len(df)}')\n",
        "\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp_L0-yhmau_"
      },
      "source": [
        "# choose which transformer model to use\n",
        "\n",
        "# ELECTRA models\n",
        "#path_to_model = r'./bert/electra-small-swedish-cased-discriminator'\n",
        "path_to_model = r'./bert/electra-base-swedish-cased-discriminator'\n",
        "\n",
        "# BERT models\n",
        "#path_to_model = r'./bert/bert-base-cased'\n",
        "#path_to_model = r'./bert/bert-base-swedish-cased'\n",
        "#path_to_model = r'./bert/bert-base-multilingual-cased'\n",
        "\n",
        "# XLNet models\n",
        "#path_to_model = r'./xlnet/xlnet-base-cased'\n",
        "\n",
        "print(f'Model path: {path_to_model}')\n",
        "summary += f'\\nModel path: {path_to_model}'\n",
        "\n",
        "tok = None\n",
        "if re.search(r'xlnet', path_to_model):\n",
        "    tok = XLNetTokenizer.from_pretrained(path_to_model)\n",
        "    print('Using XLNetTokenizer')\n",
        "    summary += f'\\nTokenizer: XLNetTokenizer'\n",
        "elif re.search(r'bert', path_to_model):\n",
        "    tok = BertTokenizer.from_pretrained(path_to_model, do_lower_case=False)\n",
        "    print('Using BertTokenizer')\n",
        "    summary += f'\\nTokenizer: BertTokenizer'\n",
        "\n",
        "# train a multilabel_binarizer on the labels\n",
        "labels = df['labels'].tolist()\n",
        "multilab_bin = MultiLabelBinarizer()\n",
        "multilab_bin.fit(labels)\n",
        "summary += f'\\nNumber of labels: {len(multilab_bin.classes_)}'\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, multilab_bin, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.multilab_bin = multilab_bin\n",
        "        self.data = dataframe\n",
        "        self.text = self.data['text']\n",
        "        self.labels = self.data['labels']\n",
        "        self.max_len = max_len\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = ' '.join(text.split())\n",
        "        \n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs['token_type_ids']\n",
        "        \n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            #'labels': torch.tensor(np.sum(self.multilab_bin.transform([self.labels[index]]), axis=0), dtype=torch.float)\n",
        "            'labels': torch.tensor(self.multilab_bin.transform([self.labels[index]]).reshape(-1,), dtype=torch.float)\n",
        "        }        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqxfp2B8mau_"
      },
      "source": [
        "batch_size = 16\n",
        "summary += f'\\nBatch size: {batch_size}'\n",
        "\n",
        "# max number of tokens in text\n",
        "max_len = 0\n",
        "for i in range(len(df['text'])):\n",
        "    text = df['text'][i]\n",
        "    inputs = tok.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            padding=False,\n",
        "            return_token_type_ids=True\n",
        "            )\n",
        "    \n",
        "    if len(inputs['input_ids']) >= max_len:\n",
        "        print(len(inputs['input_ids']))\n",
        "        print(df['text'][i])\n",
        "        print(inputs['input_ids'])\n",
        "        print(tok.convert_ids_to_tokens(inputs['input_ids']))\n",
        "        max_len = len(inputs['input_ids'])\n",
        "if max_len > 250:\n",
        "    max_len = 250\n",
        "\n",
        "\n",
        "# TEMP: Manually set the max_len\n",
        "#max_len = 128\n",
        "\n",
        "print(f'Max token length: {max_len}')\n",
        "summary += f'\\nMax token sequence length: {max_len}'\n",
        "\n",
        "\n",
        "train_dataset, test_dataset = train_test_split(df,\n",
        "                                        test_size=0.2,\n",
        "                                        shuffle=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "test_dataset = test_dataset.reset_index(drop=True)\n",
        "\n",
        "train_set = CustomDataset(train_dataset, tok, multilab_bin, max_len)\n",
        "test_set = CustomDataset(test_dataset, tok, multilab_bin, max_len)\n",
        "\n",
        "train_params = {'batch_size': batch_size,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "               }\n",
        "test_params = {'batch_size': batch_size,\n",
        "               'shuffle': True,\n",
        "               'num_workers': 0\n",
        "              }\n",
        "\n",
        "train_loader = DataLoader(train_set, **train_params)\n",
        "test_loader = DataLoader(test_set, **test_params)\n",
        "\n",
        "print(f'Train set: {len(train_dataset)} samples')\n",
        "print(f'Test set: {len(test_dataset)} samples')\n",
        "\n",
        "summary += f'\\nTraining set: {len(train_dataset)} samples\\nTest set: {len(test_dataset)} samples'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHjybrQHmau_"
      },
      "source": [
        "# decide which device to use. use cuda if available\n",
        "dev = ''\n",
        "if torch.cuda.is_available():\n",
        "    dev = 'cuda:0'\n",
        "    summary += f'\\nCUDA device: {torch.cuda.get_device_name(0)}'\n",
        "else:\n",
        "    dev = 'cpu'\n",
        "    summary += '\\nCUDA device: None'\n",
        "\n",
        "print(f'dev = {dev}')\n",
        "print(f'Number of available GPUs: {torch.cuda.device_count()}')\n",
        "\n",
        "# print the device names\n",
        "for i in range(torch.cuda.device_count()):\n",
        "  print(f'Device {i}: {torch.cuda.get_device_name(i)}')\n",
        "\n",
        "device = torch.device(dev)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBYDTZNvmavA"
      },
      "source": [
        "class BERTClass(nn.Module):\n",
        "    def __init__(self, config, path_to_bert, output_dim):\n",
        "        super(BERTClass, self).__init__()\n",
        "        #config = PretrainedConfig.from_json_file(f'{path_to_bert}/config.json')\n",
        "        self.bert = BertModel.from_pretrained(path_to_bert)\n",
        "        #self.bert = BertModel(config)\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.fc = nn.Linear(config.hidden_size, output_dim)\n",
        "        self.sigm = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        x = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
        "        x = self.dropout(x[1])\n",
        "        x = self.fc(x)\n",
        "        output = self.sigm(x)\n",
        "        return output\n",
        "\n",
        "class XLNetClass(nn.Module):\n",
        "    def __init__(self, config, path_to_model, output_dim):\n",
        "        super(XLNetClass, self).__init__()\n",
        "        self.transformer = XLNetModel.from_pretrained(path_to_model)\n",
        "\n",
        "        # - - - - Imitate BertPooler - - - -\n",
        "        #self.dense = nn.Linear(config.d_model, config.d_model)\n",
        "        #self.tanh = nn.Tanh()\n",
        "        # - - - - - - - - - - - - - - - - - - -\n",
        "\n",
        "        self.dropout = nn.Dropout(config.summary_last_dropout)\n",
        "\n",
        "        self.fc = nn.Linear(config.d_model, output_dim)\n",
        "        self.sigm = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        x = self.transformer(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
        "\n",
        "        # - - - - Imitate BertPooler - - - -\n",
        "        x = x[0][:, -1] # use the CLS token\n",
        "        #x = self.dense(x)\n",
        "        #x = self.tanh(x)\n",
        "        # - - - - - - - - - - - - - - - - - -\n",
        "\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        output = self.sigm(x)\n",
        "        return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGGhVr_tmavA"
      },
      "source": [
        "# compute the loss of an epoch by averaging all batch losses\n",
        "def epoch_loss(model, data_loader, criterion):\n",
        "    loss = 0\n",
        "    batch_count = 0\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx,batch in enumerate(data_loader):\n",
        "            ids = batch['ids'].to(device, dtype=torch.long)\n",
        "            mask = batch['mask'].to(device, dtype=torch.long)\n",
        "            token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
        "            labels = batch['labels'].to(device, dtype=torch.float)\n",
        "            \n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            loss += criterion(outputs, labels)\n",
        "            batch_count += 1\n",
        "    model.train()\n",
        "    return loss / batch_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr7rj2zwWj0K"
      },
      "source": [
        "# define the model\r\n",
        "D_out = len(multilab_bin.classes_)\r\n",
        "\r\n",
        "config = PretrainedConfig.from_json_file(f'{path_to_model}/config.json')\r\n",
        "\r\n",
        "# choose appropriate nn.module class based on pathname\r\n",
        "model = None\r\n",
        "if re.search(r'xlnet', path_to_model):\r\n",
        "    model = XLNetClass(config, path_to_model, D_out)\r\n",
        "    #print('Using XLNetClass')\r\n",
        "    summary += '\\nUModel class: XLNetClass'\r\n",
        "elif re.search(r'bert', path_to_model):\r\n",
        "    model = BERTClass(config, path_to_model, D_out)\r\n",
        "    #print('Using BertClass')\r\n",
        "    summary += '\\nModel class: BertClass'\r\n",
        "\r\n",
        "model.train()\r\n",
        "model.to(device)\r\n",
        "\r\n",
        "# number of epochs trained\r\n",
        "epochs_trained = 0\r\n",
        "\r\n",
        "# losses over entire train-/test-set per epoch\r\n",
        "train_losses = []\r\n",
        "test_losses = []\r\n",
        "\r\n",
        "print(summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs7jzf1amavA",
        "scrolled": false
      },
      "source": [
        "\n",
        "model.train()\n",
        "\n",
        "# training loop\n",
        "learning_rate = 5e-5\n",
        "#learning_rate = 1e-5 # 1e-5 works better for bert-multilingual\n",
        "\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# if the test loss has not improved in the last k epochs, stop training\n",
        "k = 5\n",
        "\n",
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "    # keep track of time taken per epoch\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx,batch in enumerate(train_loader):\n",
        "        ids = batch['ids'].to(device, dtype=torch.long)\n",
        "        mask = batch['mask'].to(device, dtype=torch.long)\n",
        "        token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
        "        labels = batch['labels'].to(device, dtype=torch.float)\n",
        "        \n",
        "        # forward pass\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "        \n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # backward pass\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    # save the losses\n",
        "    train_losses.append(epoch_loss(model, train_loader, criterion))\n",
        "    test_losses.append(epoch_loss(model, test_loader, criterion))\n",
        "\n",
        "    epochs_trained += 1\n",
        "    \n",
        "    print(f'End of epoch {epochs_trained}, Train Loss: {train_losses[-1]:.7f}, Test Loss: {test_losses[-1]:.7f}, Time elapsed: {time.time()-start_time:.2f} s')\n",
        "\n",
        "    # if the test loss has not improved in the last k epochs break\n",
        "    if len(test_losses) > k and all(test_losses[-(k+1)] < tl for tl in test_losses[-k:]):\n",
        "      print(f'Test loss has not improved in the last {k} epochs. Stopping ...')\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-OJN96cmavB"
      },
      "source": [
        "# get the predicitons and corresponding labels\n",
        "def get_pred_true(model, data_loader, D_out):\n",
        "\n",
        "    y_pred = np.zeros((1,D_out))\n",
        "    y_true = np.zeros((1,D_out))\n",
        "  \n",
        "    with torch.no_grad():\n",
        "        for idx,batch in enumerate(data_loader):\n",
        "            ids = batch['ids'].to(device, dtype=torch.long)\n",
        "            mask = batch['mask'].to(device, dtype=torch.long)\n",
        "            token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
        "            labels = batch['labels'].to(device, dtype=torch.float)\n",
        "            \n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            \n",
        "            y_pred = np.concatenate((y_pred,outputs.detach().cpu().numpy()), axis=0)\n",
        "            y_true = np.concatenate((y_true,np.array(labels.cpu())), axis=0)\n",
        "            \n",
        "    return y_pred[1:,:], y_true[1:,:]\n",
        "\n",
        "model.eval()  \n",
        "y_pred_temp, y_true = get_pred_true(model, test_loader, D_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtdtWDQAmavC"
      },
      "source": [
        "# set all values above threshold to 1, else 0\n",
        "th = 0.5\n",
        "y_pred = np.copy(y_pred_temp)\n",
        "y_pred[y_pred > th] = 1\n",
        "y_pred[y_pred <= th] = 0\n",
        "\n",
        "# number of labels in test set\n",
        "#labels_in_test = np.count_nonzero(np.sum(y_true, axis=0))\n",
        "label_counts_test = np.sum(multilab_bin.transform(test_dataset['labels']), axis=0)\n",
        "labels_in_test = np.count_nonzero(label_counts_test)\n",
        "\n",
        "# number of labels in train set\n",
        "label_counts_train = np.sum(multilab_bin.transform(train_dataset['labels']), axis=0)\n",
        "labels_in_train = np.count_nonzero(label_counts_train)\n",
        "\n",
        "# compute size of intersection between labels in train and test\n",
        "label_counts_test[label_counts_test > 0] = 1\n",
        "labels_bin_test = label_counts_test\n",
        "\n",
        "label_counts_train[label_counts_train > 0] = 1\n",
        "labels_bin_train = label_counts_train\n",
        "\n",
        "labels_bin_sum = labels_bin_test + labels_bin_train\n",
        "labels_intersect = np.count_nonzero(labels_bin_sum[labels_bin_sum == 2])\n",
        "\n",
        "print(f'SEED: {SEED}')\n",
        "print(path_to_model)\n",
        "print(f'Number of labels in training set: {labels_in_train}/{y_true.shape[1]} ({labels_in_train/y_true.shape[1]*100:.2f} %)')\n",
        "print(f'Number of labels in test set: {labels_in_test}/{y_true.shape[1]} ({labels_in_test/y_true.shape[1]*100:.2f} %)')\n",
        "print(f'Number of labels present in both sets: {labels_intersect}/{y_true.shape[1]} ({labels_intersect/y_true.shape[1]*100:.2f} %)')\n",
        "print()\n",
        "print(f\"Micro-average F1-score: {f1_score(y_true, y_pred, average='micro')}\")\n",
        "print(f\"Weighted-average F1-score: {f1_score(y_true, y_pred, average='weighted', zero_division=1)}\")\n",
        "print(f\"Macro-average F1-score: {f1_score(y_true, y_pred, average='macro', zero_division=1)}\")\n",
        "#print(f\"Sample-average Jaccard score: {jaccard_score(y_true, y_pred, average='samples', zero_division=1)}\")\n",
        "print(f\"Accuracy (exact match): {accuracy_score(y_true, y_pred)}\")\n",
        "print(f\"Hamming Loss: {hamming_loss(y_true, y_pred)}\")\n",
        "\n",
        "x = [x for x in range(1,len(train_losses)+1)]\n",
        "xticks = [x*len(train_losses)//5 for x in range(1,6)]\n",
        "plt.plot(x, test_losses)\n",
        "plt.plot(x, train_losses)\n",
        "plt.legend(['Test Loss', 'Train Loss'])\n",
        "plt.xticks(xticks,xticks)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n",
        "\n",
        "# plot f1-score in relation to label frequency in training set\n",
        "f1_per_label = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
        "label_counts_train = np.sum(multilab_bin.transform(train_dataset['labels']), axis=0)\n",
        "label_counts_test = np.sum(multilab_bin.transform(test_dataset['labels']), axis=0)\n",
        "\n",
        "# also plot recall in relation to label frequency in training set\n",
        "recall_per_label = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
        "\n",
        "# only include labels that are present in the test set\n",
        "zipped = [(f1_per_label[i], recall_per_label[i], multilab_bin.classes_[i], label_counts_test[i], label_counts_train[i]) for i in range(len(label_counts_test)) if label_counts_test[i] > 0]\n",
        "zipped = sorted(zipped, key=lambda tup: tup[-1])\n",
        "\n",
        "f1_per_label = [zipped[i][0] for i in range(len(zipped))]\n",
        "recall_per_label = [zipped[i][1] for i in range(len(zipped))]\n",
        "label_counts_train = [zipped[i][-1] for i in range(len(zipped))]\n",
        "\n",
        "# plot f1-score in relation to label frequency in training set\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1,1,1)\n",
        "plt.plot(label_counts_train, f1_per_label)\n",
        "plt.plot(label_counts_train, f1_per_label, '.')\n",
        "ax.set_xscale('log')\n",
        "ax.set_ylim((0,1))\n",
        "plt.xlabel('Label frequency in training set')\n",
        "plt.ylabel('F1-score')\n",
        "plt.grid(True, which='both', linestyle=':')\n",
        "plt.show()\n",
        "\n",
        "# plot recall in relation to label frequency in training set\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1,1,1)\n",
        "plt.plot(label_counts_train, recall_per_label, 'g')\n",
        "plt.plot(label_counts_train, recall_per_label, '.', color='#ff7f0e')\n",
        "ax.set_xscale('log')\n",
        "ax.set_ylim((0,1))\n",
        "plt.xlabel('Label frequency in training set')\n",
        "plt.ylabel('Recall')\n",
        "plt.grid(True, which='both', linestyle=':')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf0Rhz2q9KV_"
      },
      "source": [
        "# write custom text for testing out the model\r\n",
        "\r\n",
        "text = ''\r\n",
        "\r\n",
        "inputs = tok.encode_plus(\r\n",
        "    text,\r\n",
        "    None,\r\n",
        "    add_special_tokens=True,\r\n",
        "    max_length=max_len,\r\n",
        "    truncation=True,\r\n",
        "    padding='max_length',\r\n",
        "    return_token_type_ids=True\r\n",
        ")\r\n",
        "ids = torch.tensor(inputs['input_ids'], dtype=torch.long).view(1,-1).to(device)\r\n",
        "mask = torch.tensor(inputs['attention_mask'], dtype=torch.long).view(1,-1).to(device)\r\n",
        "token_type_ids = torch.tensor(inputs['token_type_ids'], dtype=torch.long).view(1,-1).to(device)\r\n",
        "\r\n",
        "# get the prediction\r\n",
        "y_pred_row = model(ids, mask, token_type_ids).detach().cpu()\r\n",
        "\r\n",
        "y_pred_row[y_pred_row > th] = 1\r\n",
        "y_pred_row[y_pred_row <= th] = 0\r\n",
        "\r\n",
        "# print symptoms\r\n",
        "print(multilab_bin.inverse_transform(y_pred_row))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZQ1B-mOmavC",
        "scrolled": true
      },
      "source": [
        "model.eval()\n",
        "\n",
        "# get a list of tuples containing the samples sorted by loss\n",
        "sorted_samples = []\n",
        "\n",
        "for i in range(len(test_dataset)):\n",
        "    text = str(test_dataset['text'][i])\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    inputs = tok.encode_plus(\n",
        "        text,\n",
        "        None,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_len,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        return_token_type_ids=True\n",
        "    )\n",
        "    ids = torch.tensor(inputs['input_ids'], dtype=torch.long).view(1,-1).to(device)\n",
        "    mask = torch.tensor(inputs['attention_mask'], dtype=torch.long).view(1,-1).to(device)\n",
        "    token_type_ids = torch.tensor(inputs['token_type_ids'], dtype=torch.long).view(1,-1).to(device)\n",
        "    \n",
        "    # get the prediction\n",
        "    y_pred_row = model(ids, mask, token_type_ids).detach().cpu()\n",
        "\n",
        "    # get the true labels\n",
        "    y_true_row = torch.tensor(multilab_bin.transform([test_dataset['labels'][i]]), dtype=torch.float)\n",
        "\n",
        "    # get the loss\n",
        "    loss = criterion(y_pred_row, y_true_row)\n",
        "\n",
        "    # convert predictions according to threshold\n",
        "    y_pred_row[y_pred_row > th] = 1\n",
        "    y_pred_row[y_pred_row <= th] = 0\n",
        "\n",
        "    # get the suggested labels\n",
        "    y_suggested_row = test_dataset['suggested'][i]\n",
        "\n",
        "    sorted_samples.append((y_pred_row, y_true_row, y_suggested_row, text, loss))\n",
        "\n",
        "# sort samples with regard to loss\n",
        "sorted_samples = sorted(sorted_samples, key=lambda tup: tup[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmnfecMFmavD"
      },
      "source": [
        "# print the m percent best/worst predictions based on loss\r\n",
        "m = 50\r\n",
        "best_worst = 'worst'\r\n",
        "\r\n",
        "nbr_elements = (len(test_dataset) * m) // 100\r\n",
        "\r\n",
        "top_m = []\r\n",
        "if best_worst == 'best':\r\n",
        "  top_m = sorted_samples[:nbr_elements]\r\n",
        "elif best_worst == 'worst':\r\n",
        "  top_m = sorted_samples[len(sorted_samples)-nbr_elements:]\r\n",
        "else:\r\n",
        "  print('Please choose either \"best\" or \"worst\"')\r\n",
        "\r\n",
        "for i in range(len(top_m)):\r\n",
        "  tup = top_m[i]\r\n",
        "  pred = multilab_bin.inverse_transform(tup[0])\r\n",
        "  labels = multilab_bin.inverse_transform(tup[1])\r\n",
        "  suggested = [id2sym[j] for j in tup[2] if j in id2sym]\r\n",
        "  text = tup[3]\r\n",
        "  loss = tup[-1]\r\n",
        "\r\n",
        "  print(f'Loss: {loss}')\r\n",
        "  print(f'{text}')\r\n",
        "  print(f'Prediction: {pred}')\r\n",
        "  print(f'Labels: {labels}')\r\n",
        "  print(f'Suggested: {suggested}')\r\n",
        "  print('- - - - - - - - - - - - - - - - - - - - - - - - -')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1wAgyf_r9wl"
      },
      "source": [
        "# checkout the tokenizer\r\n",
        "max_len = 20\r\n",
        "\r\n",
        "text = 'Plants perform photosynthesis.'\r\n",
        "\r\n",
        "inputs = tok.encode_plus(\r\n",
        "            text,\r\n",
        "            None,\r\n",
        "            add_special_tokens=True,\r\n",
        "            #max_length=max_len,\r\n",
        "            #truncation=True,\r\n",
        "            #padding='max_length',\r\n",
        "            return_token_type_ids=True\r\n",
        "        )\r\n",
        "\r\n",
        "print(inputs['input_ids'])\r\n",
        "print(inputs['token_type_ids'])\r\n",
        "print(inputs['attention_mask'])\r\n",
        "print(tok.convert_ids_to_tokens(inputs['input_ids']))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}