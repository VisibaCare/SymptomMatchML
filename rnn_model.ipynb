{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4V4du-Uio_PV",
    "outputId": "7755d7a8-a31c-4e5b-ed58-debaa27d2a7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49ui7QY2pDFp",
    "outputId": "d6feaf2c-9fd6-431b-83bf-9e14a75b6c63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/exjobb_project\n",
      "/content/drive/MyDrive/exjobb_project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.getcwd() == '/content':\n",
    "  % cd drive/MyDrive/exjobb_project\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9DZ8_MoqozSX"
   },
   "outputs": [],
   "source": [
    "# metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import regex as re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import BCELoss\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "b8JLV36KozSY"
   },
   "outputs": [],
   "source": [
    "path_to_data = './data'\n",
    "\n",
    "# create dataframe from sessions.json\n",
    "df = pd.read_json(f'{path_to_data}/sessions.json')\n",
    "df.head()\n",
    "\n",
    "# create dictionaries for switching between symptom and id\n",
    "id2sym = {}\n",
    "sym2id = {}\n",
    "\n",
    "with open(f'{path_to_data}/symptoms.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    for sym in data:\n",
    "        id2sym[sym['id']] = sym['name']\n",
    "        sym2id[sym['name']] = sym['id']\n",
    "        \n",
    "        \n",
    "# remove labels that have less than m occurrences\n",
    "m = 0\n",
    "\n",
    "labels_list = df['confirmed'].tolist()\n",
    "labels_list = sum(labels_list, [])\n",
    "c = Counter(labels_list)\n",
    "for i in range(len(df)):\n",
    "    to_remove = []\n",
    "    \n",
    "    # find labels that should be removed \n",
    "    for j in range(len(df['confirmed'][i])):\n",
    "        if c[df['confirmed'][i][j]] < m:\n",
    "            to_remove.append(j)\n",
    "            \n",
    "    # remove the labels\n",
    "    shift = 0\n",
    "    for j in range(len(to_remove)):\n",
    "        df['confirmed'][i].pop(to_remove[j]-shift)\n",
    "        shift += 1\n",
    "    \n",
    "        \n",
    "# add column with the symptom names\n",
    "sym_names = []\n",
    "\n",
    "for syms in df['confirmed']:\n",
    "    if len(syms) != 0:\n",
    "        sym_names.append([id2sym[x] for x in syms])\n",
    "    else:\n",
    "        sym_names.append([])\n",
    "\n",
    "df['labels'] = sym_names\n",
    "\n",
    "# remove all rows with no confirmed labels\n",
    "df = df[df['confirmed'].map(len) > 0]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "pzv2HOX1ozSZ",
    "outputId": "cd1c6b8a-db53-4208-8dca-4609c9d6447a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Slut på medicin.</td>\n",
       "      <td>[Känd astma, Känd lungsjukdom]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Behöver att prata med psykolog angående använd...</td>\n",
       "      <td>[Nedstämdhet, Trötthet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Har fått besvärlig eksem på händerna</td>\n",
       "      <td>[Hudbesvär, Synliga hudbesvär]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muskelsvaghet och trötthet känner mig skakig o...</td>\n",
       "      <td>[Muskelsvaghet, Trötthet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Svår smärta i vänsterhanden/handleden precis n...</td>\n",
       "      <td>[Smärta i handled eller fingrar, Förvärras av ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                                             labels\n",
       "0                                   Slut på medicin.                     [Känd astma, Känd lungsjukdom]\n",
       "1  Behöver att prata med psykolog angående använd...                            [Nedstämdhet, Trötthet]\n",
       "2              Har fått besvärlig eksem på händerna                      [Hudbesvär, Synliga hudbesvär]\n",
       "3  Muskelsvaghet och trötthet känner mig skakig o...                          [Muskelsvaghet, Trötthet]\n",
       "4  Svår smärta i vänsterhanden/handleden precis n...  [Smärta i handled eller fingrar, Förvärras av ..."
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('confirmed', inplace=True, axis=1)\n",
    "df.drop('suggested', inplace=True, axis=1)\n",
    "#df = df[0:500]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fdk9K-ANozSa",
    "outputId": "39bcc069-9812-4e98-e66f-c966ffa41c95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hej', 'hur', 'är', 'läget', 'sdfs']\n"
     ]
    }
   ],
   "source": [
    "# a basic tokenizer to start off with\n",
    "def basic_tokenization(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    tokens = re.sub(r'[^\\p{L} ]', ' ', text).split()\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "test = 'Hej, hur är läget?sdfs'\n",
    "print(basic_tokenization(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0x2IW7_cE5nI",
    "outputId": "938b406f-b32b-49ec-d6f8-61e3249bbc17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pretrained embeddings ...\n",
      "[192250, 300]\n"
     ]
    }
   ],
   "source": [
    "# create dictionary that assigns a unique integer id for each word in the embeddings\n",
    "word2id = {}\n",
    "id_count = 0\n",
    "\n",
    "use_pretrained = True\n",
    "embedding_weights = None\n",
    "\n",
    "# ids for padding and unkown tokens \n",
    "pad_tok = None\n",
    "unk_tok = None\n",
    "\n",
    "if use_pretrained:\n",
    "  print('Using pretrained embeddings ...')\n",
    "  with open('./embeddings/swectors-300dim.txt', encoding='utf-8') as file:\n",
    "      # initialize the embedding weights matrix with zeros\n",
    "      dims = [int(x) for x in file.readline().split()]\n",
    "      print(dims)\n",
    "      embedding_weights = torch.zeros((dims[0],dims[1]), dtype=torch.float64)    \n",
    "      \n",
    "      line = file.readline().split()\n",
    "      while line != []:\n",
    "          word2id[line[0]] = id_count\n",
    "          embedding_weights[id_count,:] = torch.tensor([float(x) for x in line[1:]])\n",
    "          id_count += 1\n",
    "          \n",
    "          line = file.readline()\n",
    "          line = line.split()\n",
    "          \n",
    "      pad_tok = word2id['<>']\n",
    "      unk_tok = word2id['<>det']\n",
    "else:\n",
    "  print('Not using pretrained embeddings ...')\n",
    "  pad_tok = 0\n",
    "  unk_tok = 1\n",
    "  id_count += 2\n",
    "\n",
    "  for i in range(len(df)):\n",
    "    text = df['text'][i]\n",
    "    tokens = basic_tokenization(text)\n",
    "\n",
    "    for tok in tokens:\n",
    "      if tok not in word2id:\n",
    "        word2id[tok] = id_count\n",
    "        id_count += 1\n",
    "  print(f'Vocabulary size: {len(word2id)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "P0R5lOB2ozSc"
   },
   "outputs": [],
   "source": [
    "# train a multilabel_binarizer on the labels\n",
    "labels = df['labels'].tolist()\n",
    "multilab_bin = MultiLabelBinarizer()\n",
    "multilab_bin.fit(labels)\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, word2id, multilab_bin, unk_tok):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.word2id = word2id\n",
    "        self.multilab_bin = multilab_bin\n",
    "        self.data = dataframe\n",
    "        self.text = self.data['text']\n",
    "        self.labels = self.data['labels']\n",
    "        self.unk_tok = unk_tok\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        tokens = self.tokenizer(text)\n",
    "        # if tokens is empty, add set tokens to ['x']\n",
    "        if len(tokens) <= 1:\n",
    "            tokens = ['x']\n",
    "        \n",
    "        text_len = len(tokens)\n",
    "        ids = [0 for i in range(len(tokens))]\n",
    "        for i in range(len(tokens)):\n",
    "            if tokens[i] in word2id:\n",
    "                ids[i] = word2id[tokens[i]]\n",
    "            else:\n",
    "                ids[i] = self.unk_tok\n",
    "        \n",
    "        return {\n",
    "            'lens': text_len,\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'labels': torch.tensor(np.sum(self.multilab_bin.transform([self.labels[index]]), axis=0), dtype=torch.float)\n",
    "        }      \n",
    "    \n",
    "# collate function for the dataloader\n",
    "def collate_fn(batch):\n",
    "    # sort token-id sequences by length\n",
    "    for_sorting = [(batch[i]['lens'],batch[i]['ids'],batch[i]['labels']) for i in range(len(batch))]\n",
    "    for_sorting = sorted(for_sorting, key=lambda tup: tup[0], reverse=True)\n",
    "    \n",
    "    # pad token-id sequences to max_len_batch\n",
    "    max_len_batch = for_sorting[0][0]\n",
    "    \n",
    "    lens = [0 for i in range(len(batch))]\n",
    "    ids = torch.zeros((len(batch), max_len_batch), dtype=torch.long)\n",
    "    labels = torch.zeros((len(batch), len(batch[0]['labels'])))\n",
    "    \n",
    "    for i in range(len(batch)):\n",
    "        temp = torch.tensor([pad_tok for j in range(max_len_batch)])\n",
    "        temp[:for_sorting[i][0]] = for_sorting[i][1]\n",
    "        \n",
    "        lens[i] = for_sorting[i][0]\n",
    "        ids[i,:] = temp\n",
    "        labels[i,:] = for_sorting[i][2]\n",
    "        \n",
    "    return lens, ids, labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zjhY4k_uozSc",
    "outputId": "38059a00-2c00-49cf-8eaa-1c95e5b5b728"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "Train set: 3027 samples\n",
      "Test set: 757 samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# max number of tokens in text\n",
    "max_len = 0\n",
    "for i in range(len(df['text'])):\n",
    "    text = df['text'][i]\n",
    "            \n",
    "    tokens = basic_tokenization(text)\n",
    "    \n",
    "    if len(tokens) > max_len:\n",
    "        max_len = len(tokens)\n",
    "\n",
    "print(max_len)\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(df,\n",
    "                                        random_state=42,\n",
    "                                        test_size=0.2,\n",
    "                                        shuffle=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "test_dataset = test_dataset.reset_index(drop=True)\n",
    "\n",
    "train_set = CustomDataset(train_dataset, basic_tokenization, word2id, multilab_bin, unk_tok)\n",
    "test_set = CustomDataset(test_dataset, basic_tokenization, word2id, multilab_bin, unk_tok)\n",
    "\n",
    "train_params = {'batch_size': batch_size,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0,\n",
    "                'collate_fn': collate_fn\n",
    "               }\n",
    "test_params = {'batch_size': batch_size,\n",
    "               'shuffle': True,\n",
    "               'num_workers': 0,\n",
    "               'collate_fn': collate_fn\n",
    "              }\n",
    "\n",
    "train_loader = DataLoader(train_set, **train_params)\n",
    "test_loader = DataLoader(test_set, **test_params)\n",
    "\n",
    "print(f'Train set: {len(train_dataset)} samples')\n",
    "print(f'Test set: {len(test_dataset)} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LY8cCk9_ozSd",
    "outputId": "1d5808e0-b6f7-4712-f1ff-b8dea54d1c8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev = cuda:0\n",
      "Number of available GPUs: 1\n",
      "Device 0: Tesla P4\n"
     ]
    }
   ],
   "source": [
    "# decide which device to use. use cuda if available\n",
    "dev = ''\n",
    "if torch.cuda.is_available():\n",
    "    dev = 'cuda:0'\n",
    "else:\n",
    "    dev = 'cpu'\n",
    "\n",
    "print(f'dev = {dev}')\n",
    "print(f'Number of available GPUs: {torch.cuda.device_count()}')\n",
    "\n",
    "# print the device names\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f'Device {i}: {torch.cuda.get_device_name(i)}')\n",
    "\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "estS0oVZozSd"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, embeddings, hidden_dim, output_dim):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.word_embeddings = None\n",
    "        embedding_dim = 0\n",
    "        if embeddings != None:\n",
    "          # initialize embeddings and make them untrainable\n",
    "          embedding_dim = embeddings.shape[1]\n",
    "          self.word_embeddings = nn.Embedding.from_pretrained(embeddings)\n",
    "          #self.word_embeddings.weight.requires_grad = False\n",
    "        else:\n",
    "          embedding_dim = 100\n",
    "          self.word_embeddings = nn.Embedding(id_count, embedding_dim)\n",
    "\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(2*hidden_dim, output_dim)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "        \n",
    "    # sentences contains padded token-id sequences sorted by length\n",
    "    def forward(self, sentences, sent_lengths):\n",
    "        embeds = self.word_embeddings(sentences)\n",
    "        \n",
    "        # pack_padded_sequnce so that padded items won't be shown to the RNN\n",
    "        if len(sent_lengths) > 1:\n",
    "            X = torch.nn.utils.rnn.pack_padded_sequence(embeds, sent_lengths, batch_first=True)\n",
    "        else:\n",
    "            X = embeds.view(1,sent_lengths[0],-1)\n",
    "        \n",
    "        X = X.float()\n",
    "        _, hc = self.rnn(X)\n",
    "        \n",
    "        # make use of the final hidden state\n",
    "        X = hc[0]\n",
    "        \n",
    "        # undo the packing\n",
    "        #X, _ = torch.nn.utils.rnn.pad_packed_sequence(X, batch_first=True)\n",
    "        \n",
    "        # reshape X to fit the linear layer\n",
    "        X = torch.cat((X[0,:,:],X[1,:,:]), 1)\n",
    "        \n",
    "        X = self.fc(X)\n",
    "        X = self.sigm(X)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "GM4I7iasozSd"
   },
   "outputs": [],
   "source": [
    "# compute the loss of an epoch by averaging all batch losses\n",
    "def epoch_loss(model, data_loader, criterion):\n",
    "    loss = 0\n",
    "    batch_count = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx,batch in enumerate(data_loader):\n",
    "            lens, ids, labels = batch\n",
    "            lens = torch.tensor(lens, dtype=torch.long)#.to(device)\n",
    "            ids = ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(ids, lens)\n",
    "            loss += criterion(outputs, labels)\n",
    "            batch_count += 1\n",
    "    model.train()\n",
    "    return loss / batch_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SYxcOHjYozSe"
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "output_dim = len(multilab_bin.classes_)\n",
    "hidden_dim = 500\n",
    "if embedding_weights != None: embedding_weights = embedding_weights.to(device)\n",
    "\n",
    "model = RNN(embedding_weights, hidden_dim, output_dim)\n",
    "model.train()\n",
    "model.to(device)\n",
    "\n",
    "# number of epochs trained\n",
    "epochs_trained = 0\n",
    "\n",
    "# losses over entire train-/test-set per epoch\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-PROe1XUozSe",
    "outputId": "f02b0925-7fe2-4f47-dde1-a4e917ae0cf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 41, Train Loss: 0.0177080, Test Loss: 0.0285148\n",
      "End of epoch 42, Train Loss: 0.0173162, Test Loss: 0.0283089\n",
      "End of epoch 43, Train Loss: 0.0168246, Test Loss: 0.0284360\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "# training loop\n",
    "learning_rate = 0.00005\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# if the test loss has not improved in the last k epochs, stop training\n",
    "k = 5\n",
    "\n",
    "num_epochs = 40\n",
    "for epoch in range(num_epochs):\n",
    "    for idx,batch in enumerate(train_loader):\n",
    "        lens, ids, labels = batch\n",
    "        lens = torch.tensor(lens, dtype=torch.long)#.to(device)\n",
    "        ids = ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(ids, lens)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # backward pass\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # save the losses\n",
    "    train_losses.append(epoch_loss(model, train_loader, criterion))\n",
    "    test_losses.append(epoch_loss(model, test_loader, criterion))\n",
    "\n",
    "    epochs_trained += 1\n",
    "    \n",
    "    print(f'End of epoch {epochs_trained}, Train Loss: {train_losses[-1]:.7f}, Test Loss: {test_losses[-1]:.7f}')\n",
    "    \n",
    "    # if the test loss has not improved in the last k epochs break\n",
    "    if len(test_losses) > k and all(test_losses[-(k+1)] < tl for tl in test_losses[-k:]):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "XsAoIyRjozSf"
   },
   "outputs": [],
   "source": [
    "# get the predicitons and corresponding labels\n",
    "def get_pred_true(model, data_loader, D_out):\n",
    "\n",
    "    y_pred = np.zeros((1,D_out))\n",
    "    y_true = np.zeros((1,D_out))\n",
    "  \n",
    "    with torch.no_grad():\n",
    "        for idx,batch in enumerate(data_loader):\n",
    "            lens, ids, labels = batch\n",
    "            lens = torch.tensor(lens, dtype=torch.long)#.to(device)\n",
    "            ids = ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(ids, lens)\n",
    "            \n",
    "            y_pred = np.concatenate((y_pred,outputs.detach().cpu().numpy()), axis=0)\n",
    "            y_true = np.concatenate((y_true,np.array(labels.cpu())), axis=0)\n",
    "            \n",
    "    return y_pred[1:,:], y_true[1:,:]\n",
    "\n",
    "model.eval()  \n",
    "y_pred_temp, y_true = get_pred_true(model, test_loader, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "9zHmy5LMozSf",
    "outputId": "f2861ed9-29da-4332-b119-841da12b6003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels in training set: 186/197 (94.42 %)\n",
      "Number of labels in test set: 140/197 (71.07 %)\n",
      "Number of labels present in both sets: 129/197 (65.48 %)\n",
      "\n",
      "Micro-average F1-score: 0.5193171608265948\n",
      "Weighted-average F1-score: 0.42438562604731495\n",
      "Macro-average F1-score: 0.3270247143924751\n",
      "Accuracy (exact match): 0.22721268163804492\n",
      "Hamming Loss: 0.007174996144277773\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set all values above threshold to 1, else 0\n",
    "th = 0.5\n",
    "y_pred = np.copy(y_pred_temp)\n",
    "y_pred[y_pred > th] = 1\n",
    "y_pred[y_pred <= th] = 0\n",
    "\n",
    "# number of labels in test set\n",
    "#labels_in_test = np.count_nonzero(np.sum(y_true, axis=0))\n",
    "label_counts_test = np.sum(multilab_bin.transform(test_dataset['labels']), axis=0)\n",
    "labels_in_test = np.count_nonzero(label_counts_test)\n",
    "\n",
    "# number of labels in train set\n",
    "label_counts_train = np.sum(multilab_bin.transform(train_dataset['labels']), axis=0)\n",
    "labels_in_train = np.count_nonzero(label_counts_train)\n",
    "\n",
    "# compute size of intersection between labels in train and test\n",
    "label_counts_test[label_counts_test > 0] = 1\n",
    "labels_bin_test = label_counts_test\n",
    "\n",
    "label_counts_train[label_counts_train > 0] = 1\n",
    "labels_bin_train = label_counts_train\n",
    "\n",
    "labels_bin_sum = labels_bin_test + labels_bin_train\n",
    "labels_intersect = np.count_nonzero(labels_bin_sum[labels_bin_sum == 2])\n",
    "\n",
    "print(f'Number of labels in training set: {labels_in_train}/{y_true.shape[1]} ({labels_in_train/y_true.shape[1]*100:.2f} %)')\n",
    "print(f'Number of labels in test set: {labels_in_test}/{y_true.shape[1]} ({labels_in_test/y_true.shape[1]*100:.2f} %)')\n",
    "print(f'Number of labels present in both sets: {labels_intersect}/{y_true.shape[1]} ({labels_intersect/y_true.shape[1]*100:.2f} %)')\n",
    "print()\n",
    "print(f\"Micro-average F1-score: {f1_score(y_true, y_pred, average='micro')}\")\n",
    "print(f\"Weighted-average F1-score: {f1_score(y_true, y_pred, average='weighted', zero_division=1)}\")\n",
    "print(f\"Macro-average F1-score: {f1_score(y_true, y_pred, average='macro', zero_division=1)}\")\n",
    "#print(f\"Sample-average Jaccard score: {jaccard_score(y_true, y_pred, average='samples', zero_division=1)}\")\n",
    "print(f\"Accuracy (exact match): {accuracy_score(y_true, y_pred)}\")\n",
    "print(f\"Hamming Loss: {hamming_loss(y_true, y_pred)}\")\n",
    "\n",
    "x = [x for x in range(1,len(train_losses)+1)]\n",
    "xticks = [x*len(train_losses)//5 for x in range(1,6)]\n",
    "plt.plot(x, test_losses)\n",
    "plt.plot(x, train_losses)\n",
    "plt.legend(['Test Loss', 'Train Loss'])\n",
    "plt.xticks(xticks,xticks)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "#plt.gca().set_ylim([0,0.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "sQ2nbUNTozSg"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# get a list of tuples containing the samples sorted by loss\n",
    "sorted_samples = []\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    text = str(test_dataset['text'][i])\n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "    tokens = basic_tokenization(text)\n",
    "    # if tokens is empty, add set tokens to ['x']\n",
    "    if len(tokens) <= 1:\n",
    "        tokens = ['x']\n",
    "\n",
    "    text_len = len(tokens)\n",
    "    ids = [0 for j in range(len(tokens))]\n",
    "    for j in range(len(tokens)):\n",
    "        if tokens[j] in word2id:\n",
    "            ids[j] = word2id[tokens[j]]\n",
    "        else:\n",
    "            ids[j] = unk_tok\n",
    "\n",
    "    text_len = torch.tensor([text_len], dtype=torch.long).cpu()\n",
    "    ids = torch.tensor(ids, dtype=torch.long).to(device)\n",
    "    \n",
    "    y_pred_row = model(ids, text_len).detach().cpu()#.numpy()\n",
    "    y_true = torch.tensor(multilab_bin.transform([test_dataset['labels'][i]]), dtype=torch.float)\n",
    "    \n",
    "    loss = criterion(y_pred_row, y_true)\n",
    "\n",
    "    # turn y_pred_row to ones and zeros based on threshold 'th'\n",
    "    y_pred_row[y_pred_row > th] = 1\n",
    "    y_pred_row[y_pred_row <= th] = 0\n",
    "\n",
    "    sorted_samples.append((y_pred_row, y_true, test_dataset['text'][i], loss))\n",
    "\n",
    "    if False:\n",
    "      print(text)\n",
    "      print(f'Prediction: {multilab_bin.inverse_transform(y_pred_row)}')\n",
    "      print(f'Labels: {test_dataset[\"labels\"][i]}')\n",
    "      print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n",
    "\n",
    "sorted_samples = sorted(sorted_samples, key=lambda tup: tup[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwe6d2uRozSg"
   },
   "outputs": [],
   "source": [
    "# print the m percent best/worst predictions based on loss\n",
    "m = 10\n",
    "best_worst = 'best'\n",
    "\n",
    "nbr_elements = (len(test_dataset) * m) // 100\n",
    "\n",
    "top_m = []\n",
    "if best_worst == 'best':\n",
    "  top_m = sorted_samples[:nbr_elements]\n",
    "elif best_worst == 'worst':\n",
    "  top_m = sorted_samples[len(sorted_samples)-nbr_elements:]\n",
    "else:\n",
    "  print('Please choose either \"best\" or \"worst\"')\n",
    "\n",
    "for i in range(len(top_m)):\n",
    "  tup = top_m[i]\n",
    "  pred = multilab_bin.inverse_transform(tup[0])\n",
    "  labels = multilab_bin.inverse_transform(tup[1])\n",
    "  text = tup[2]\n",
    "  loss = tup[3]\n",
    "\n",
    "  print(f'Loss: {loss}')\n",
    "  print(f'{text}')\n",
    "  print(f'Prediction: {pred}')\n",
    "  print(f'Labels: {labels}')\n",
    "  print('- - - - - - - - - - - - - - - - - - - - - - - - -')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9nyRGILozSg",
    "outputId": "993cd5f8-c91e-4075-c094-382096b18b9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[()]\n"
     ]
    }
   ],
   "source": [
    "text = ''\n",
    "#text = str(test_dataset['text'][i])\n",
    "text = ' '.join(text.split())\n",
    "\n",
    "tokens = basic_tokenization(text)\n",
    "# if tokens is empty, add set tokens to ['x']\n",
    "if len(tokens) <= 1:\n",
    "    tokens = ['x']\n",
    "\n",
    "text_len = len(tokens)\n",
    "ids = [0 for i in range(len(tokens))]\n",
    "for i in range(len(tokens)):\n",
    "    if tokens[i] in word2id:\n",
    "        ids[i] = word2id[tokens[i]]\n",
    "    else:\n",
    "        ids[i] = unk_tok\n",
    "\n",
    "text_len = torch.tensor([text_len], dtype=torch.long).cpu()\n",
    "ids = torch.tensor(ids, dtype=torch.long).to(device)\n",
    "\n",
    "y_pred_row = model(ids, text_len).detach().cpu()#.numpy()\n",
    "\n",
    "y_pred_row[y_pred_row > th] = 1\n",
    "y_pred_row[y_pred_row <= th] = 0\n",
    "\n",
    "print(multilab_bin.inverse_transform(y_pred_row))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "rnn_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
